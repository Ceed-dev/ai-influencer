# Video Analytics Hub - Context

This file maintains the complete project history for AI continuity.

## Project Purpose

Manage the complete AI influencer video production lifecycle: component management, video production planning, multi-platform analytics (YouTube Shorts / TikTok / Instagram Reels), and AI-driven improvement recommendations.

## Key IDs and Resources

| Resource | ID / URL |
|----------|----------|
| Master Spreadsheet | `1fI1s_KLcegpiACJYpmpNe9tnQmnZo2o8eHIXNV5SpPg` |
| Apps Script Project | `1nbGkujRb6PwtkVuxBh1Vb9NKIUFi_uBa8NbdPSEx_PoxREmyMUKivA0S` |
| Root Drive Folder (AI-Influencer) | `1KRQuZ4W7u5CXRamjvN4xmavfu-7TPb0X` |
| Web App Deployment URL | `https://script.google.com/macros/s/{DEPLOYMENT_ID}/exec` (created via `clasp deploy`) |
| GitHub Repository | `Ceed-dev/ai-influencer` (旧: `video-analytics-hub`) |

### Inventory Spreadsheet IDs (stored in Script Properties)

These are auto-generated by `setupCompleteSystem()` and stored in GAS Script Properties:
- `SCENARIOS_INVENTORY_ID`
- `MOTIONS_INVENTORY_ID`
- `CHARACTERS_INVENTORY_ID`
- `AUDIO_INVENTORY_ID`

---

## Session History

### 2026-02-06: Project Initialization (v1.0)

**What was done:**
- Created project folder structure
- Created initial documentation (README.md, ARCHITECTURE.md, CONTEXT.md)
- Defined GAS project structure with component breakdown
- Established Google Sheets schema for multi-platform metrics

**Key decisions:**
1. **GAS over GCP VM**: Chose Google Apps Script for simplicity and native Sheets integration
2. **video_uid linking**: Each video gets a unique ID to link across platforms
3. **CSV-first approach**: Platform APIs have severe limitations. CSV export is the primary data source

### 2026-02-06: Phase 2-5 Implementation (v1.0)

**What was done:**
- CSV parsers, normalizers, linkers, KPI engine, LLM analyzer, sheet writer
- 223 tests across 6 test suites
- n8n integration documentation
- Sample CSV files

### 2026-02-09: Complete v2.0 Rebuild

**Why v2.0 was needed:**
- v1.0 was analytics-only (CSV import and analysis). It had no concept of video production lifecycle, no component management, and no way to track which content elements contributed to performance.
- v2.0 adds the complete production loop: component inventories, production workflow, approval gates, component-aware AI analysis, and performance scoring.

**What was done:**

- **Phase 1: Foundation**
  - `Config.gs` - Complete rewrite with Drive structure, master columns, component types, ID prefixes, KPI defaults, column aliases, dropdown options, colors
  - `Utils.gs` - Added readSheetAsObjects, findRowByColumn, findAllRowsByColumn, updateRowByIndex, ID generators (generateVideoUid, generateComponentId, generateScenarioId, generateMotionId, generateCharacterId, generateAudioId), getInventoryTypeFromId, getComponentById, getComponentsById
  - `Setup.gs` - One-click system setup: creates Drive folders (Scenarios/Motions/Characters/Audio/Analytics with subfolders), inventory spreadsheets (4 separate spreadsheets), all master sheet tabs, demo data, KPI defaults, formatting (dropdowns, conditional colors, checkbox)
  - `Migration.gs` - v1 to v2 migration (renames videos_master to master, adds new columns, creates video_analysis sheet, updates recommendations schema)

- **Phase 2: Data Layer**
  - `ComponentManager.gs` (NEW) - Component CRUD (addComponent, updateComponent, archiveComponent), listComponents with filters (type/status/tags), getTopPerformingComponents, buildVideoComponentContext, incrementComponentUsage, getComponentPerformanceHistory, buildRecommendationComponentPool
  - `MasterManager.gs` (NEW) - Master sheet operations (createProduction, getVideosByStatus, getApprovedVideos, getProductionData), production workflow (updateVideoStatus, approveVideo), updateMetricsSnapshot, writeAIRecommendations, updateAnalysisResults, getAllVideoUids, getMasterData
  - `ScoreUpdater.gs` (NEW) - updateAllComponentScores, calculateAvgScore, updateComponentScoresForVideo, updateSingleComponentScore, normalizeOverallScore, getScoreSummary

- **Phase 3: Analysis Extension**
  - `LLMAnalyzer.gs` - Rewritten with component-aware prompts (analyzWithLLMEnhanced), includes component history and top performers in AI context, generates component-specific recommendations via separate prompt, single-video analysis with component context
  - `Linker.gs` - Updated for v2.0 master sheet references, added updateMasterMetricsSnapshot
  - `KPIEngine.gs` - Added normalizeOverallScore for cross-platform scoring
  - `SheetWriter.gs` - Added writeToInventory, writeVideoAnalysis, writeRecommendationsEnhanced, clearAllData

- **Phase 4: Integration**
  - `Code.gs` - Complete rewrite with 13 API actions (doGet: get_status, get_approved, get_production, get_components, get_score_summary; doPost: import_csv, analyze, analyze_single, analyze_all, link_videos, create_production, approve_video, update_status, add_component, update_component, get_components, update_scores)
  - UI menu with submenus: Import CSV (YouTube/TikTok/Instagram), Analyze (Single/All), Production (Create/Approve/Status), Components (Add/Browse/Scores)

- **Phase 5: Testing**
  - 3 new test files: ComponentManager.test.js, MasterManager.test.js, ScoreUpdater.test.js
  - Updated all existing tests for v2.0 (master sheet references, removed scenario_cuts)
  - Updated setup.js with all v2.0 utility mocks
  - **330 tests passing across 9 test suites**

- **Phase 6: Documentation**
  - Updated all documentation for v2.0

**Key v2.0 decisions:**
1. **Separate inventory spreadsheets**: Each component type (scenarios, motions, characters, audio) has its own spreadsheet, accessed via `SpreadsheetApp.openById()`
2. **Component ID system**: Prefix-based (SCN_H_, SCN_B_, SCN_C_, MOT_, CHR_, AUD_) for type identification
3. **Production workflow**: draft -> approved -> in_production -> published -> analyzed, with human approval gate
4. **Component-aware AI analysis**: AI receives full component context (history, scores, top performers) when analyzing

### 2026-02-09: v2.0.1 - Checkbox Bug Fix

**Problem:** The `human_approved` checkbox column in the master sheet was causing `getLastRow()` to return 101 instead of 2 (or the actual data row count), because `requireCheckbox()` data validation auto-fills `FALSE` into empty cells, making them appear as data rows.

**Fix:** Changed `applyMasterSheetFormatting_()` to only apply checkbox validation to rows that have actual data (checked `sheet.getLastRow()` before applying), rather than applying to a range of 100 rows.

**Commit:** `62f7400 Fix insertDemoData false positive: checkbox FALSE values triggered data check`

### 2026-02-09: v2.0.2 - appendRow Bug Fix

**Problem:** Because of the checkbox FALSE values filling up to row 101, `sheet.appendRow()` was writing new data at row 102 instead of the next available row after actual data.

**Fix:** Updated `insertDemoData()` to clear any existing rows (including checkbox FALSE values) before writing demo data, and then apply checkbox validation only to the data rows.

**Commit:** `4c36712 Fix checkbox causing appendRow to write at row 101 instead of row 2`

### 2026-02-09: v2.0.3 - Config Sheet Fallback for API Keys

**Problem:** Setting Script Properties via the Apps Script editor is cumbersome, especially for the OpenAI API key. The `_config` sheet in the spreadsheet provides a more accessible way to store configuration.

**What changed:**
- `Config.gs`: Added `getConfigFromSheet_()` function that reads from a `_config` sheet (columns: key, value, description) as a fallback when Script Properties are not set
- `Config.gs`: Added `migrateConfigToProperties()` to migrate _config sheet values to Script Properties
- `OPENAI_API_KEY` now reads from Script Properties first, then falls back to `_config` sheet

### 2026-02-09: v2.0.4 - Web App Access Configuration

**Problem:** The Web App was not accessible externally because `appsscript.json` had `oauthScopes` configured (for bound script) but no `webapp` section. The webapp needed to be accessible without authentication for n8n integration.

**What changed:**
- `appsscript.json`: Replaced `oauthScopes` array with `webapp` configuration:
  ```json
  "webapp": {
    "access": "ANYONE_ANONYMOUS",
    "executeAs": "USER_DEPLOYING"
  }
  ```
- This allows anyone with the deployment URL to access the Web App endpoints
- OAuth scopes are inferred automatically by GAS for bound scripts

### 2026-02-09: OAuth Setup for Google Sheets/Drive API

**Purpose:** Enable Claude Code to directly read/write to Google Sheets and Drive for E2E testing and debugging.

**What was set up:**
- Created OAuth 2.0 credentials in Google Cloud Console (project: video-analytics-hub)
- Created `scripts/gsheet.py` CLI utility for direct Sheets/Drive API access
- Token stored in `.gsheets_token.json` (gitignored)
- OAuth client credentials in `video_analytics_hub_claude_code_oauth.json` (gitignored)
- MCP servers configured in `.mcp.json` for google-workspace and google-sheets integration (gitignored)

### 2026-02-09: E2E Testing Results

**End-to-end testing was performed against the live spreadsheet:**
- Confirmed all 9 sheet tabs exist with correct headers
- Confirmed master sheet has 3 demo videos (2 analyzed, 1 draft)
- Confirmed metrics sheets have data for analyzed videos
- Confirmed KPI targets are set with default values
- Confirmed component inventories are connected and populated with demo data
- All 330 unit tests pass

### 2026-02-09: LLM Analysis Execution (Live Test)

**Live test of the analysis pipeline was verified:**
- OpenAI API key configured via `_config` sheet (auto-migrated to Script Properties)
- `analyzeVideoSingle` and `analyzeAllVideosEnhanced` functions tested via GAS editor execution
- Analysis writes to `video_analysis` and `recommendations` sheets
- Component scores updated after analysis
- AI-recommended components written to `ai_next_*` columns

### 2026-02-09: MANUAL.md Creation

**Created comprehensive Japanese-language user manual (`MANUAL.md`):**
- Complete system overview with architecture diagrams (ASCII art)
- Detailed Google Drive data structure documentation
- All spreadsheet schemas with column descriptions
- Component management workflows
- Video production lifecycle documentation
- CSV import procedures for all 3 platforms
- Analysis and KPI explanation
- AI recommendation and approval flow
- n8n/API integration guide with all endpoint specifications
- GAS menu operation guide
- Troubleshooting section
- Initial setup instructions

### 2026-02-09: v2.1.0 - Documentation Update and .gitignore Hardening

**What was done:**
- Updated CONTEXT.md with complete project history
- Added `.mcp.json` and `tmp/` to `.gitignore` to prevent credential leaks
- Verified all documentation files are consistent with v2.0 codebase
- Committed, pushed, and deployed to Apps Script

### 2026-02-09: v3.0.0 - AI-Influencer Pipeline

**Why:** Pivot from analytics-only tool to a full content production pipeline. The existing GAS analytics (v2.0) handles post-publication analysis well, but the upstream workflow (video generation → platform posting) was manual via n8n. This version adds an automated Node.js pipeline to handle end-to-end content production at scale (50 → 700 accounts).

**What was done:**

- **Project restructure**: Renamed conceptually from "Video Analytics Hub" to "AI-Influencer" to reflect the broader scope
- **Created `pipeline/` directory** with modular Node.js architecture:
  - `pipeline/config.js` - Environment configuration and API key management
  - `pipeline/orchestrator.js` - Pipeline orchestration (scenario → video → post)
  - `pipeline/sheets/reader.js` - Google Sheets API reader (scenarios, accounts)
  - `pipeline/sheets/writer.js` - Google Sheets API writer (pipeline status, results)
  - `pipeline/media/kling.js` - fal.ai Kling video generation
  - `pipeline/media/tts.js` - fal.ai ElevenLabs TTS
  - `pipeline/media/lipsync.js` - fal.ai Lipsync processing
  - `pipeline/media/creatify.js` - Creatify video composition
  - `pipeline/storage/drive.js` - Google Drive upload/management
  - `pipeline/posting/youtube.js` - YouTube Data API v3 posting
  - `pipeline/posting/instagram.js` - Instagram Graph API posting
  - `pipeline/posting/tiktok.js` - TikTok Content Posting API
  - `pipeline/posting/x.js` - X/Twitter v2 API posting
- **Created `scripts/` entry points**:
  - `scripts/run-pipeline.js` - Single video pipeline execution
  - `scripts/run-daily.js` - Daily batch execution for all accounts
  - `scripts/collect-metrics.js` - Metrics collection from platforms
- **New Google Sheets tabs designed**:
  - `accounts` - Platform account management (account_id, platform, credentials_ref, status, daily limits)
  - `content_pipeline` - Pipeline execution log (pipeline_id, video_uid, account_id, job IDs, status, cost)
- **Documentation rewrite**:
  - `STRATEGY.md` (NEW) - Strategy, KPI targets, revenue model, meeting notes, decision log
  - `README.md` - Complete rewrite for AI-Influencer scope
  - `ARCHITECTURE.md` - Complete rewrite with Pipeline + Analytics architecture
  - `CONTEXT.md` - Appended this session

**Key decisions:**
1. **Node.js pipeline (not GAS)**: GAS has 6-minute timeout and can't handle long-running video generation. Node.js runs on local/server with no timeout constraints
2. **fal.ai as media hub**: Consolidates Kling, ElevenLabs, and Lipsync under one API provider
3. **Google Sheets as DB**: Continues using Sheets for simplicity and compatibility with existing GAS analytics
4. **YouTube first for MVP**: Most stable API, fastest path to revenue
5. **Existing GAS analytics unchanged**: The 14 GAS files and 330 tests remain untouched

**Phase plan:**
- Phase 1 (2/10-12): MVP - 1 account, YouTube auto-posting
- Phase 2 (2/13-17): 12 YouTube + 12 Instagram accounts
- Phase 3 (2/18-28): All 50 accounts across 4 platforms

### 2026-02-10: Phase 0 - Content Generation Pipeline Implementation

**Why:** The n8n workflow analysis revealed 5 critical differences between the existing pipeline code and the actual production workflow. The pipeline needed to be rewritten to match the real n8n flow exactly.

**What was done:**

- **n8n workflow analysis**: Analyzed `ワークフロー.json` and `senario_template.xlsx` to extract the real 3-step process (Kling → TTS → Lipsync, no Creatify Aurora)
- **Created `pipeline/data/scenario.json`**: Extracted 3 sections (hook, body, cta) with scripts and motion reference video Drive IDs (`motionVideoDriveId`)
- **Fixed media module endpoints**:
  - `video-generator.js`: `image-to-video` → `motion-control` with `video_url`, `character_orientation` (NO `prompt` or `keep_original_sound` — causes 422)
  - `tts-generator.js`: `tts/v3` → `tts/eleven-v3` with voice name "Aria" instead of voice_id
  - `lipsync.js`: `v2` → `v2/pro` with `sync_mode: "bounce"`
- **Added fal.storage upload**: `uploadToFalStorage()` and `downloadFromDrive()` in `fal-client.js` — replaces Cloudinary with Drive → fal.storage → API pattern
- **Created ffmpeg concat utility**: `pipeline/media/concat.js` using concat demuxer for combining 3 section videos
- **Rewrote orchestrator**: New 3-section loop — downloads motion video from Drive per section → fal.storage → Kling → TTS → Lipsync, then ffmpeg concat + Drive upload (4 files) + sheet logging
- **Rewrote CLI**: `--character-folder <DRIVE_FOLDER_ID>` replaces `--account`
- **Deleted Cloudinary and Compositor modules**: Removed `compositor.js`, `cloudinary.js`, cloudinary config and dependency
- **Updated content_pipeline sheet schema**: New columns (character_folder_id, section_count, hook/body/cta_video_url, drive_folder_id)
- **Updated content-manager.js**: HEADERS array matches new sheet schema
- **Created pipeline test suite**: 21 tests covering modules, endpoints, ffmpeg, CLI, schema, edge cases
- **Updated Jest config**: Projects-based config for both GAS and pipeline test suites
- **E2E success**: First full pipeline run completed — CNT_202602_2916 (54MB final video, 3 sections)
  - Uploaded CHR_0001_v1.jpg to `Characters/Images/CHR_0001/`
  - Fixed `FAL_KEY || FAL_AI_KEY` fallback in config.js
  - Replaced dead Cloudinary URLs in scenario.json with Drive file IDs (motionVideoDriveId)
  - Removed invalid `prompt: ''` and `keep_original_sound: true` params from video-generator
  - Output: `Productions/2026-02-10/CNT_202602_2916/` with 4 MP4 files uploaded to Drive
  - content_pipeline sheet updated with status=completed and all Drive links
- **README.md rewritten**: Comprehensive specification document with pipeline flow, service descriptions, Drive folder structure, all Sheets schemas with column-level documentation, setup, usage, cost structure

**Key decisions:**
1. **Creatify Aurora removed**: n8n workflow doesn't use it — the 3-step process (Kling → TTS → Lipsync) is sufficient
2. **Cloudinary → fal.storage**: All persistent files in Drive, temporary URLs via fal.storage. No external image hosting needed
3. **3-section structure**: Each video consists of hook + body + cta, processed independently then concatenated
4. **ffmpeg for concatenation**: Simple `concat demuxer` with `-c copy` (no re-encoding) for fast joining
5. **Drive folder structure**: Productions/YYYY-MM-DD/CNT_XXXX/ with 4 files per content
6. **Motion videos from Drive**: scenario.json stores Drive file IDs (not URLs), orchestrator downloads + uploads to fal.storage per section

**Test results:** 351 tests passing (330 GAS + 21 pipeline)

---

## Current System State (as of 2026-02-10)

### Deployed and Working (GAS Analytics v2.0)
- Master Spreadsheet with all 9 tabs initialized and formatted
- 4 Component Inventory spreadsheets (Scenarios, Motions, Characters, Audio)
- Google Drive folder structure (AI-Influencer root with all subfolders)
- Web App deployed with anonymous access
- OpenAI integration working (via _config sheet fallback)
- Demo data: 3 videos (2 analyzed with metrics, 1 draft)
- Demo components: 7 scenarios, 5 motions, 3 characters, 4 audio
- All 330 GAS tests passing

### Implemented (Pipeline Phase 0 - 2026-02-10) — E2E Verified
- Content generation pipeline: character image → 3-section video → Drive — **working end-to-end**
- First successful E2E: CNT_202602_2916 (54MB final video, ~35min processing time)
- 3 media modules (Kling motion-control, ElevenLabs eleven-v3, Lipsync v2/pro)
- fal.storage upload (replaces Cloudinary)
- ffmpeg concat utility for 3-section video joining
- Orchestrator: downloads motion videos from Drive → fal.storage per section, 3-section loop, Drive upload, sheet logging
- CLI: `node scripts/run-pipeline.js --character-folder <ID> [--dry-run]`
- content_pipeline sheet with new schema (15 columns) — 3 records (2 error during dev, 1 completed)
- Character image CHR_0001_v1.jpg uploaded to Drive `Characters/Images/CHR_0001/`
- Output stored at `Productions/2026-02-10/CNT_202602_2916/` (4 MP4 files)
- README.md rewritten as comprehensive specification (pipeline flow, services, Drive structure, all Sheets schemas)
- 21 pipeline tests passing

### Pending
- Platform posting automation (Phase 2)
- Metrics collection automation (Phase 3)
- GAS analytics integration with pipeline content_pipeline data
- Batch execution for multiple accounts (Phase 1)
- GAS analytics loop integration (Phase 3)

### Files in Repository
```
gas/                        # GAS analytics (unchanged)
  Code.gs                   # Web App endpoints + UI menu (1157 lines)
  Config.gs                 # Settings, schema, constants (389 lines)
  Setup.gs                  # One-click system setup (762 lines)
  Migration.gs              # v1 to v2 migration (224 lines)
  CSVParser.gs              # Platform-specific CSV parsers (190 lines)
  Normalizer.gs             # Unified schema conversion (208 lines)
  Linker.gs                 # video_uid matching (238 lines)
  KPIEngine.gs              # KPI comparison (249 lines)
  LLMAnalyzer.gs            # OpenAI integration (665 lines)
  SheetWriter.gs            # Sheet write operations (275 lines)
  ComponentManager.gs       # Component CRUD + context (283 lines)
  MasterManager.gs          # Master sheet + workflow (255 lines)
  ScoreUpdater.gs           # Component scoring (212 lines)
  Utils.gs                  # ID generators, helpers (544 lines)
  appsscript.json           # GAS manifest
  tests/                    # 9 test suites, 330 tests

pipeline/                   # Node.js content pipeline (Phase 0 complete)
  config.js                 # Environment configuration (no cloudinary/elevenlabs)
  orchestrator.js           # 3-section pipeline (Kling → TTS → Lipsync → concat)
  data/scenario.json        # Scenario template (3 sections: hook, body, cta)
  sheets/client.js          # Google Sheets/Drive API (OAuth2)
  sheets/account-manager.js # Accounts tab CRUD
  sheets/content-manager.js # Content pipeline tab CRUD (updated schema)
  media/fal-client.js       # fal.ai SDK + fal.storage upload + Drive download
  media/video-generator.js  # Kling v2.6 motion-control
  media/tts-generator.js    # ElevenLabs eleven-v3 (voice: Aria)
  media/lipsync.js          # Sync Lipsync v2/pro (sync_mode: bounce)
  media/concat.js           # ffmpeg concat demuxer
  storage/drive-storage.js  # Video URL → Drive upload
  posting/poster.js         # Unified posting interface (stub)
  posting/adapters/*.js     # Platform adapters (stubs)

tests/                      # Pipeline tests (new)
  pipeline.test.js          # 21 tests

scripts/                    # CLI entry points
  run-pipeline.js           # --character-folder <ID> [--dry-run]
  run-daily.js              # Daily batch execution (stub)
  collect-metrics.js        # Metrics collection (stub)
  gsheet.py                 # Google Sheets CLI utility (existing)

docs/
  USER_GUIDE.md             # Japanese user guide
  n8n-integration.md        # n8n workflow integration guide

STRATEGY.md                 # Strategy, KPI, meeting notes (new)
README.md                   # Project README (rewritten)
ARCHITECTURE.md             # System architecture (rewritten)
CONTEXT.md                  # This file - project history
MANUAL.md                   # GAS user manual (Japanese)
```

---

## Technical Notes

### Platform CSV Column Variations

YouTube may change column names between exports. Known variations:
- "Views" / "View count" / "視聴回数"
- "Watch time (hours)" / "総再生時間（時間）"

TikTok variations:
- "Video views" / "Views"
- "Average watch time" / "Avg. watch time"

Instagram variations:
- "Plays" / "Views"
- "Reach" / "Accounts reached"

### GAS Limitations to Remember
- 6-minute execution timeout
- 20MB response size limit
- 100 triggers per user limit
- Properties Service: 500KB total, 9KB per property

### OpenAI Integration Notes
- Use TSV output format for structured responses (more reliable parsing than JSON)
- Batch multiple videos per request to reduce API calls
- Implement exponential backoff for rate limiting
- v2.0: Include component context for better recommendations

### v2.0 Component Score System
- Each analyzed video's overall_score contributes to its components' avg_performance_score
- Scores normalized 0-100 across platforms
- Top-performing components surfaced in AI recommendation prompts
- Score updates cascade: video analyzed -> master updated -> all linked components updated

### Sensitive Data Locations (NOT in git)
- `.clasp.json` - clasp config with Script ID
- `.gsheets_token.json` - OAuth token for Sheets/Drive API
- `video_analytics_hub_*oauth*.json` - OAuth client credentials
- `client_secret_*.json` - Google Cloud client secrets
- `.mcp.json` - MCP server config with OAuth credentials
- `_config` sheet in spreadsheet - contains OpenAI API key
