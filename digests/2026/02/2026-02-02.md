---
date: 2026-02-02
channel: ceed-aiインフルエンサー
messages: 11
threads: 8
participants: 4
generated_at: 2026-02-17T04:07:06.806Z
---

# Slack日報: 2026年2月2日 (ceed-aiインフルエンサー)

## サマリー

### 本日のトピック
- Twitterの公式APIの利用に関するディスカッション
- 自動化プロセスの進捗と問題点
- 動画生成APIの改善とテスト
- コンテンツ分析と投稿後のパフォーマンス分析の方法
- システムアーキテクチャーの見直し

### 決定事項
- TwitterのAPI利用について、安定性の観点から申請を行うことを決定 [15:14]
- 自動化の進捗に関し、会議を18時に行うことを決定 [15:49]
- 動画生成に関して、Creatify Auroraを使用する方向で進める [14:02]

### アクションアイテム
- Badhan: Twitter APIの申請を行う
- Badhan: 自動化プロセスについて、進捗を共有し、会議を設定する
- 鈴田智仁: 自動化のエラー対処法を見直し、改善案を準備する
- Zach: 自動化プロセスの議論に参加
- 鈴田智仁: 動画生成のプロンプト調整とツールのテストを行う
- Badhan: 自動化プロセス関連のアカウント準備

### 重要な議論
- 自動化プロセスでのAPIエラーの問題について [15:57]: 動くものはできたが、APIエラーで度々停止するため、エラー発生時に再試行する仕組みを検討。
- コンテンツ生成の改善 [21:08]: AIを活用したコンテンツの構成や喋り方、キャラクターデザインについて議論し、分析方法を模索。
- システムアーキテクチャーの見直し [12:38]: n8nを使ったワークフローとGoogle Apps Scriptの融合により、パフォーマンスデータの分析と報告の効率化を検討。

### 共有リンク・資料
- Twitter公式APIの従量課金版情報: [https://console.x.com/#features](https://console.x.com/#features)
- 自動化進捗報告フォーム: [https://docs.google.com/forms/d/e/1FAIpQLSdcoYqLIJ3-No8oMUc8oxsjaRIhaS-bdbd-NPt-Hx_LPXjiQw/viewform](https://docs.google.com/forms/d/e/1FAIpQLSdcoYqLIJ3-No8oMUc8oxsjaRIhaS-bdbd-NPt-Hx_LPXjiQw/viewform)
- 動画生成API関連: [https://elevenlabs.io/ja](https://elevenlabs.io/ja), [https://fal.ai/models/veed/fabric-1.0](https://fal.ai/models/veed/fabric-1.0), その他関連ツールリンク
- その他参考資料: [https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM](https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM), [https://chatgpt.com/share/698049d6-aa3c-8004-b32a-52176627c2df](https://chatgpt.com/share/698049d6-aa3c-8004-b32a-52176627c2df)

### メモ
- 他のアカウントが垢BANされた理由を明確にする必要性を確認。
- 動画生成のプロンプト改善の試行錯誤が進行中。
- 自動化プロセスのさらなる細分化と効率化の議論が進行中。

## 統計
- メッセージ数: 11 / スレッド数: 8 / 参加者: 4名

## 会話ログ
<details>
<summary>全会話ログを展開 (11 messages)</summary>

### 10:17 JST - 鈴田智仁 ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1769995049662819))
<https://console.x.com/#features|https://console.x.com/#features>
Twitterの公式apiから従量課金バージョンでてる

> **スレッド (2件):**
> 15:12 - 鈴田智仁: <@U023YG4NDB8>
<https://docs.google.com/forms/d/e/1FAIpQLSdcoYqLIJ3-No8oMUc8oxsjaRIhaS-bdbd-NPt-Hx_LPXjiQw/viewform>

xの公式のAPIが使えるなら安定性的に考えても使いたいので申請してみて欲しいです！
> 15:14 - Badhan: 了解です！

### 14:23 JST - 鈴田智仁 ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770009836066169))
ngoc 1投稿目

### 14:24 JST - 鈴田智仁 ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770009842895779))
polypolitics1投稿目

### 15:22 JST - Badhan ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770013322954039))
<@U09RBQP1J78> 金曜日に話した自動化部分の進捗何かあれば今日軽くお話ししたいです！

> **スレッド (12件):**
> 15:34 - Zach(高橋勇作): これ話す時、僕も入れてください！
> 15:48 - 鈴田智仁: <@U023YG4NDB8> <@U0245FFV18B>
一旦文章ベースでまとめるのでそれみて軽く話しましょうか！
> 15:49 - Badhan: 了解です。何時だと話せそうですか？
会議室押さえます
> 15:51 - Badhan: <@U0245FFV18B> 18時~で大丈夫そう？
> 15:53 - Zach(高橋勇作): うん、なんなら会議室抑えて考え事してるだけだから何時でもok
> 15:57 - 鈴田智仁: • 自動リプについて
    ◦ 動くものはできたが、apiエラーがちょこちょこでてて止まったりしてるので、エラーが出たらやり直すみたいな感じに分岐する様に今調整中です！
• 投稿→分析→改善の自動化について
    ◦ 投稿の自動化についてはリプと同じ感じでAPIをつかってスケジュールを組めば可能
    ◦ 分析→改善について
        ▪︎ n8nだけだと自動で学習して評価してというのは、難しそう（分析させたり自動投稿はできるが学習していくという部分が弱そう）
            • lang graphと組み合わせと良さそう（実装コストが見積りきれていない）
        ▪︎ gptでリサーチした結果　<https://chatgpt.com/share/698049d6-aa3c-8004-b32a-52176627c2df>

> 16:42 - Badhan: *メモ*
• MTGまでに解像度をもう少し上げる
• 全体の可能な部分と不可能な部分を切り分け
• 全体ワークフローのセッティング工数（日単位）を大まかに出す
• （着手の優先順位もできれば）
> 16:47 - 鈴田智仁: <https://www.notion.so/2fbfd18968c380a3bed0ea555e00a6c3?source=copy_link>

一旦ここに解像度を上げたバージョンをまとめてます
まだ大まかな工数入れてないのでそこもいれます
> 16:47 - Badhan: ありがとうございます！
> 18:00 - 鈴田智仁: 少し遅れます！
> 18:03 - Badhan: Jackの会議室にいますので終わったらそのまま来てもらえれば！:man-gesturing-ok:
> 18:06 - 鈴田智仁: 今から行きます！

### 19:00 JST - 鈴田智仁 ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770026453961439))
音声生成API
<https://elevenlabs.io/ja>
動画生成API
<https://fal.ai/models/veed/fabric-1.0>

> **スレッド (8件):**
> 12:49 - 鈴田智仁: <@U023YG4NDB8>
一旦、ワークフローできてます
<https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM>

ただ昨日見せた動画生成部分に使ったのがこのfabric1.0ってやつなんですけど、リップシンクに特化しててアニメーションを指定することができなかったです（最初に手を挙げるなどを再現するのが難しい）

試しに画像をそもそも腕を上げたものにして試してみたのですが微妙そう

なので動画生成部分を他のものに変えようと思ってます

候補がこの2つでいま出力どうか試してみてます
<https://creatify.ai/ja/introducing-aurora>
<https://www.infinitetalk.net/infinitetalk>

出力がいい感じだったらワークフローの動画生成部分のAPIを変更するだけなのですぐに変えれそうです
> 13:13 - Badhan: ありがとうございます！
そうですね。なんかお化けみたいですね笑笑

他のツールを試してどうだったか教えてほしいです
> 13:23 - 鈴田智仁: infinitytalkでgeminiに参考動画いれて試しにつくったプロンプトで動画作ったらプロンプトは反映されてるみたいだが再現できてない動画ができました

文字ベースのプロンプトの質向上でどうにかなるのか、それともvideo to videoのAIで参考動画のキャラだけ変えるみたいな方がいいかなど考えたいですね

geminiの会話
<https://gemini.google.com/share/d68769156ea2>

<https://www.infinitetalk.net/infinitetalk>
```プロンプト
A photorealistic medium shot of a young woman with long dark wavy hair, wearing a casual grey ribbed tank top, sitting in a cozy bedroom with warm lighting.

Action sequence:
1. She is looking directly at the camera and talking expressively.
2. While talking, she raises both arms to gather her hair back.
3. She swiftly ties her hair into a messy high bun using a hair tie.
4. After tying her hair, she points her finger at the camera to emphasize her point.

Style:
Social media vlog aesthetic, authentic, high resolution, sharp focus on the face, natural skin texture, realistic movement, eye contact maintained throughout the action.```
> 13:31 - 鈴田智仁: <https://fal.ai/models/fal-ai/creatify/aurora>

creatify auroraで作成したバージョン

プロンプトが再現できてないだけ説ありました
こっちだと割と自然なのでプロンプトを調整して試してみます
> 13:46 - 鈴田智仁: プロンプト改善したらマシになってきた
> 13:47 - 鈴田智仁: gptに作らせたプロンプト
```Vertical 9:16 UGC TikTok selfie video, ultra-realistic smartphone footage, static front-facing camera at eye level, medium shot (waist-up) of a young adult brunette woman seated on a chair in a cozy bedroom. Warm golden-hour sunlight from the right side with soft shadows, natural skin texture, slight handheld phone feel but mostly steady. Background: beige/tan paneled wall, a bed on the right with a wooden headboard and a patterned duvet, subtle warm lamp glow in the back. Wardrobe: light gray ribbed cropped tank top; a hint of red sweatpants at the bottom edge of frame. Natural casual makeup, expressive eyes, friendly confident tone reminding a creator giving advice.

Performance and motion: She looks directly into the lens the entire time with natural blinking and subtle head nods. Start with both hands near the sides of her head/temples, then raise both arms behind her head as if gathering her hair. Around 1.0s she holds a messy bun pose with both hands up behind her head. Around 2.2s she releases the hair so it falls down over her shoulders and transitions into explaining mode, lifting one hand to gesture and briefly raising an index finger for emphasis. Final moment: she leans slightly forward and points down/inward with both hands near the bottom of the frame to punctuate the last word. Keep gestures natural and synced to the speech rhythm, no exaggerated cartoon motion.

On-screen text overlay: TikTok-style subtitles, small bold white text with thin black outline/shadow, centered in the lower third (above the waist). The subtitle changes in 4 short segments timed to the spoken line:
1) "Burnout does not come"
2) "from working too hard"
3) "it comes from working"
4) "inefficiently"
Clean overlay, no extra graphics, no logos.```
> 14:02 - 鈴田智仁: とりあえずcreatify auroraを使う形でプロンプトを生成するところの精度をあげていけばある程度いけそう
> 14:29 - Badhan: いい感じです！！

### 19:08 JST - 鈴田智仁 ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770026935513139))
<@U02A6MHJSMP>
<https://docs.twitterapi.io/api-reference/endpoint/get_all_community_tweets>

> **スレッド (10件):**
> 19:11 - pochi_udon: <https://docs.twitterapi.io/api-reference/endpoint/tweet_advanced_search>
> 19:14 - pochi_udon: 人間はアプリ上で自然言語で指示をする。それをAIが解釈して適切なパラメータを持ったクエリを作成してAPIを呼び出す。そのアウトプットをスプシにまとめる。
> 11:28 - pochi_udon: Advanced Searchエンドポイントを統合して、そのアウトプットをまるまるスプシの「X」タブにまとめるというふうにしたけど、どう？動いている？
-> <https://script.google.com/macros/s/AKfycbzIWez-fcxZ3gynYFZGhIk2VM-IvYHyLVyekBqjZjiCIPBUfl4Uk7rS2SCNts3lUHTM/exec>
あと、トモさんはアプリの使用権限とその後の作成されてシートの閲覧権限はある？
cc: <@U023YG4NDB8>
> 11:30 - 鈴田智仁: みてみます！
> 11:37 - 鈴田智仁: 出色結果のスプシの権限はなかったのでリクエストしました！
> 11:37 - pochi_udon: 許可した！
> 11:39 - pochi_udon: このプロダクトの関連フォルダ全体にアクセスできるようにしておいた。
> 15:27 - pochi_udon: <@U09RBQP1J78> どうだった？想定通りに挙動している？
> 15:55 - 鈴田智仁: • Collect 30 tweets about AI from @elonmusk
このプロンプトで結果がこんなかんじだから結構微妙かも
<https://docs.google.com/spreadsheets/d/1znUCuSzgR_a2jw_-tKXHoG-Tt8MrWFewT1nu2v5bvuM/edit?usp=sharing>
elonmusk以外のツイートが集められているのとインスタも同時に収集してしまう
> 16:18 - pochi_udon: 了解した。あとで修正を考える。

### 20:33 JST - Badhan ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770032008093279))
<@U09RBQP1J78>
TikTok動画：<https://www.tiktok.com/@tips.withrach/video/7582042185281899789?is_from_webapp=1&amp;sender_device=pc>
Xでの発言：<https://x.com/danielhangan_/status/2016578118585053354?s=20>

＝＝＝＝＝＝＝＝＝＝＝
とりあえずのコンテンツの型化をこれで進めたいです。
• 女の人
• 服装は同じテイストで（とりあえず雰囲気）
• 最初の手を上げるのがポイントっぽいので、とりあえずこれをまんまパクる
• コンテンツの中身は「AIを活用した〇〇」で統一
    ◦ AIでの仕事効率化
    ◦ 最近話題のAIツール紹介（自分がどう使っているか）
    ◦ などなど

> **スレッド (21件):**
> 20:33 - Badhan: *ちなみに大元垢バンされてます
> 20:43 - 鈴田智仁: 確認します！
> 20:47 - 鈴田智仁: これ作るのにAIの1人語りの動画以外にAIを実際に使ってる画面の撮影素材が必要ですね
> 20:48 - Badhan: いや実際使ってる画面とかは一旦無視しましょう。なんかややこしくなってくる気がするので。

＝＝＝＝＝＝＝＝
一旦シンプル版が終わったら追加で考えましょう！
> 20:49 - 鈴田智仁: そうですね！
一旦シンプル版作れるワークフロー共有します
> 21:08 - 鈴田智仁: AI動画作成

分析項目
• カット数
• １カットあたりの文字数
• カット内の表現
    ◦ 表情
    ◦ 動き
    ◦ 喋り方
以上をスプレッドシートにカットごとにまとめてプロンプトにして動画制作フローに渡して動画を作成する
> 21:08 - 鈴田智仁: 字幕についても
１字幕あたり何文字くらいか
も分析して字幕追加時に指示する
> 21:19 - Badhan: 動画に関しての情報はこの辺だけでいいんですか？
それ以外の部分は型で決まってるイメージですかね？
> 21:30 - 鈴田智仁: あとは以下も必要だと思います！

• 脚本の構成内容
    ◦ どういう流れになっているか（全体の構成）
    ◦ フックでどういう言葉使ってるかなど各カットごとの内容分析
キャラクター設定が決まっていなければ
• 人物のメタ的な特徴
    ◦ 髪型
    ◦ 顔の特徴
    ◦ 声
    ◦ 性別
    ◦ 人種
• 人物の特徴から得られる印象
あとは音関連ですかね
• bgm
• SE
がどうなっているかなど
> 21:31 - 鈴田智仁: 大きく3つの要素があると思ってて
• キャラクターデザイン
• 脚本
• 演出（喋り方や表情）
ここを要素出して分析する感じだと思ってます
> 22:16 - Badhan: *ToDo*
• スプシの清書版
• AIのプロンプト作成
• 使うツールの決定（一旦決まってる？）
> 13:39 - 鈴田智仁: <@U023YG4NDB8>
このポストに書かれてるDansUGCってサービスAIじゃなくて人間にモーションを撮ってもらって素材として送ってくれる感じみたいですね
<https://dansugc.com/>

めちゃくちゃAIって疑われてるけど
> 14:31 - Badhan: まじですか？めちゃくちゃAIっぽいですけど….モーション変換だったんですね
> 15:55 - 鈴田智仁: もとの動きだけ人間に撮らせて、AIに読み込ませてるのかもしれないですね
> 19:44 - Badhan: <@U09RBQP1J78> 状況把握させてください！！
コンテンツ生成部分はもう一定アウトプット出せそうな感じですか？



＝＝＝＝＝＝＝＝
こちらの状況共有です
駿冴に各所のAgentを作ってもらってて、それをn8nで最後くっつける感じになるかと思います。
> 19:53 - 鈴田智仁: 画像とテキストがあればアウトプット出せます！
<https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM|https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM>

参考動画を分解してプロンプトにするとこをgptのアプリ側で調整してて、それをn8n側に反映させる感じになります！
> 19:55 - Badhan: お！！ありがとうございます。
駿冴がデータのやり取り部分を作り終えたら、全体の中にそれ組み込んだらいけそうですね。:clap:


僕はアカウント準備を始めます
> 19:55 - Badhan: <https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM>
こちら僕アカウセスないみたいです
> 20:00 - 鈴田智仁: 権限追加したので確認してみてください！
> 20:01 - Badhan: もらいました！ありがとうございます
> 13:47 - Badhan: cc: <@U02A6MHJSMP>

### 20:57 JST - Badhan ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770033423724119))
めも
<https://x.com/onlinedopamine/status/2017998880051286374?s=46|https://x.com/onlinedopamine/status/2017998880051286374?s=46>

### 23:09 JST - 鈴田智仁 ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770041358833819))
<@U023YG4NDB8>
ngocの認証が外れてるみたいなので決済確認して欲しいです！

*[ファイル: スクリーンショット 2026-02-02 23.08.43.png]*

> **スレッド (8件):**
> 23:11 - Badhan: なんか自分ログインできなくなってます。。。
明日Tomoさんオフィス来ます？？
> 23:11 - Badhan: それならTomoさんの画面から課金しようと思って
> 23:15 - 鈴田智仁: FRBDNRITSL2IRKDB

2FAのキーこれでやってみてください！
> 23:15 - Badhan: なんかUser IDの時点で「メアド or 電話番号」入れてと出てきます
> 23:16 - 鈴田智仁: <mailto:herbertugaitafa9017@bblckids.com|herbertugaitafa9017@bblckids.com>
> 23:16 - 鈴田智仁: ngocのめあど多分これですね
> 23:21 - Badhan: Doneです
> 23:21 - 鈴田智仁: ありがとうございます！

### 23:13 JST - Badhan ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770041631565879))
<@U09RBQP1J78> <@U02A6MHJSMP>
ここで全体像の整理中です。とりあえず自分の知識の範囲内で吐き出してます。
AIと対話しながら精度あげつつ、2人に要所要所投げるかもです

<https://www.canva.com/design/DAHAK6xD7Sc/J4_6D1Jstv9Ts_P28LEyMQ/edit?utm_content=DAHAK6xD7Sc&amp;utm_campaign=designshare&amp;utm_medium=link2&amp;utm_source=sharebutton|https://www.canva.com/design/DAHAK6xD7Sc/J4_6D1Jstv9Ts_P28LEyMQ/edit?utm_content=DA[…]m_campaign=designshare&amp;utm_medium=link2&amp;utm_source=sharebutton>

> **スレッド (55件):**
> 16:20 - pochi_udon: • データ・メモリレイヤーはどうするか？
• タイムラインの担保（最短で動くフローができるもの）
> 16:53 - pochi_udon: <@U09RBQP1J78>
「コンテンツ作り」のフローにおいて、要件定義的にどのようなツールやプロンプトをどういった順番フローで組み合わせていこうと思っているのか、文章で簡単にまとめて後で教えて欲しい。
> 17:00 - 鈴田智仁: まとめるので少々おまちを
> 18:02 - 鈴田智仁: <https://ceed.app.n8n.cloud/workflow/4yhIH8xr15Ju7mNnE3vIM>
作ったワークフローは↑でAPIは下記を使用してます
• 動画生成
    ◦ creatify/aurora
    ◦ <https://fal.ai/models/fal-ai/creatify/aurora>
• 音声生成
    ◦ elevenlabs/tts/eleven-v3
    ◦ <https://fal.ai/models/fal-ai/elevenlabs/tts/eleven-v3/playground>
あと、参考動画の分析をgptがgeminiで行ってcreatify/auroraに送る動画生成プロンプト制作する感じで考えてます
> 18:04 - 鈴田智仁: fal aiのapiに画像や音声を送るのに一回ファイルをアップしてURL化しないといけないので
<https://cloudinary.com/>　っていうストレージに一回あげてます

これは何のダービスでも大丈夫です
> 18:26 - pochi_udon: 理解した。ありがとう。あと上記のn8nリンクについて、アクセスしようとしたらログインを求められるから、フロー全体が分かるようなスクショとフローのJSONデータの2つをここに直接送ってもらえる？一旦はその2つさえわかれば僕がログインしなくても大丈夫なので。
> 18:38 - 鈴田智仁: <@U02A6MHJSMP>
はい！
> 18:41 - 鈴田智仁: このフォームトリガーの前段階に、
• 参考動画を分析
• 分析結果からシナリオ作成
• シナリオと分析結果から動画プロンプト
の3つの要素を追加したいと思ってます

参考動画に関してはマーケットリサーチしてきたものをインプットすることを想定していて、動画の場合は1本ずつ分析する感じかなと
> 18:50 - pochi_udon: Ty!!
> 19:54 - pochi_udon: <@U09RBQP1J78>
n8nに関して <mailto:pochi@0xqube.xyz|pochi@0xqube.xyz> に対してinviteを送ってもらって良い？
あと、全然n8nに関して知識がないんだけどクラウド版のやつを使っている？アクセスしてそこで何かワークフローを作成したらそのまま動かせるようなやつ？
> 19:55 - 鈴田智仁: クラウド版！
アクセスしてノード繋げてワークフローも動かせるし、コードを自分で書いて処理させることも可能
> 19:59 - 鈴田智仁: 招待した！
> 11:02 - pochi_udon: <@U023YG4NDB8>
以下のものに関して解像度を上げた情報がまとまっているので確認をしてほしい。
-> <https://chatgpt.com/s/t_6982a7c211f88191a3307525b8ac3e1e>
※<https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770103239373969?thread_ts=1770041631.565879&cid=C09RBQH0NA2|今回の状況において優先度が高いキーポイント>（クオリティよりもまずは動くもの。そもそも動かないとクオリティが〜〇〇みたいなレベルに達する以前の問題なので。）
• （言った・言っていない問題を防ぐために）昨日の話した情報を明示的にまとめたもの、結論と理由
• その話したことを再度AIインフルエンサーの全体フローに照らし合わせた時の整合性のチェック
• 一番大切な「メモリ・データレイヤー」を、今回のn8nベースとスケジュールの制約がある中で何が一番良い選択肢なのか？理由・他の考えうる選択肢。
• それぞれのフェーズでどのようなツールを使うのかを簡潔に表形式でまとめたもの
これに基づいてAIから指示を受けて手足となって作業を引き続き進めていく。
------------------------------------
（余談・背景）
長くて読めないし理解できないということは十分に承知をしているが、リンク先のものは全て結論だけでなく理由も含めて同じものを認識しておくべき最小限だと思うので、あえてそのまま共有する。僕が結論だけを抽出して共有すると、「これってどうなの？」や「なんでこのようになっているの？」や「クオリティはどうなるの？」とか余分なコミュニケーションが発生する可能性が高いので。
> 12:27 - pochi_udon: ChatGPTのアウトプットの中で大事な部分は<https://www.notion.so/AI-2f0fd18968c38002bc9cfa5b56f88421?source=copy_link|ここのページ>内（Archiveトグルは関係無い）にまとめておいた。
履歴が消えても後から<https://www.notion.so/AI-2f0fd18968c38002bc9cfa5b56f88421?source=copy_link|このページ>で参照できるようにするために。
> 12:44 - Badhan: ありがとう。今確認する
> 12:51 - Badhan: 確認and理解した:man-gesturing-ok:
> 14:28 - 鈴田智仁: &gt; 1. 既存の「コンテンツ作り」n8n WFは、連携前に最小の整合チェックが必要  l-ai/creatify/auroraに投げているのに、ステータス確認/結果取得がveed/fabric-1 せん。
&gt;     ◦ 音声生成のテキストが "thak you" 固定になっており、フォーム入力の原稿を使っていません。
&gt; → ここは“既存担当”と握って、I/Oの契約（入力項目・出力項目）を固定するのがフリクション最小です。
ここの部分、api変えたりしたときにそのままになったりしてたので修正しますね
> 14:35 - 鈴田智仁: 修正済みです
> 16:28 - pochi_udon: <@U09RBQP1J78>
「<mailto:T.S.0131.1998@gmail.com|T.S.0131.1998@gmail.com>」に<https://www.notion.so/AI-2f0fd18968c38002bc9cfa5b56f88421?source=copy_link|Notionページ>の招待を送った。
> 12:22 - pochi_udon: <@U09RBQP1J78> 「マーケットリサーチ」やその後の「コンテンツ作成」の部分について出来ているWFから昨日共有した「AI Influencer」ワークスペース上に追加をしていってほしい。所々人が介入する部分があると思うけど、そこにhuman in the loopのノードか何かをおいて実際にデータを流してみた方が個人的に全体像が把握できて良いので。
<@U023YG4NDB8> パフォーマンス分析の部分に関してはどのような仕様になるか決まっている？投稿の部分は人間が手動で行うので、そのリンクをスプシに記入してその後の流れとして、どのタイミングで、どのようなデータを取得しにいくのかなど。あと反省・反映フェーズにおいてAIが「どのような感じで、どういったことに気をつけて反省をすれば良いのか」のプロンプトのベースラインは出来ている？
> 12:23 - 鈴田智仁: 確認します！
> 12:44 - pochi_udon: <@U09RBQP1J78> WF内で作成された成果物やメタデータなどの諸々の情報に関しては全て<https://drive.google.com/drive/folders/1KRQuZ4W7u5CXRamjvN4xmavfu-7TPb0X?usp=sharing|このドライブ>以下に保存しようと思うんだけど、大丈夫かな？（すでにトモさんの権限は付与されているはず）ここに溜めてった情報をフェーズが進むごとに他のAIなり別のノードが参照をしていくというイメージ。
> 13:23 - 鈴田智仁: おけです
いまからオフィス行くんで、14時前くらいに着くと思うんでオフィスで会話させて！
> 14:11 - Badhan: <@U02A6MHJSMP> 俺へのメンション分への返信
まだどちらも考えられてないから、今日明日で詰め切る。叩き作りに少しヘルプ必要かもしれない。
> 14:11 - Badhan: いつまでに必要なんだっけここ
> 14:19 - pochi_udon: <@U023YG4NDB8> 明日中でも大丈夫。一旦は僕の方で適当な値を入れるなり、簡易的な仕様で作成することも可能だと思うので。
> 14:20 - Badhan: じゃあそれでお願い！
> 15:12 - pochi_udon: メモ：
• コンテンツ分析の型・方針の叩きを作成：コンテンツデータを要素分解したもの（動画-&gt;①元動画の類似②カット数③感情、脚本-&gt;①構成②セリフ）とパフォーマンスデータと達成したいKPIの情報を組み合わせて、良かったのかどうか・またはその理由原因などについて分析をするための関係性を導く方針叩きの作成。
• その他のやるべきことの優先順位づけ
> 15:47 - pochi_udon: <@U023YG4NDB8> <@U09RBQP1J78>
YouTube, Tiktok, Instagramの3つのプラットフォームからエクスポートなりで取得できる「パフォーマンスデータ」の例データはある？
上記の1つ目のタスクについて方針の型を決める時にどのようなパフォーマンスデータが取得できるのかの実例が既にあったら欲しいので。
また設定するKPIとしては種類としては『Imp』だけで、それが200や500などの変数として変わるだけという認識であっている？
> 16:05 - 鈴田智仁: <https://developers.google.com/youtube/reporting/v1/reports/channel_reports?hl=ja>
youtubeのアナリティクスAPIの概要
> 16:09 - 鈴田智仁: <https://docs.google.com/spreadsheets/d/1FMkn4BaHme9Kd2lpR4HEAXYObUujYq-vcShIX1AcpQk/edit?usp=sharing>
youtubeはこんな感じのデータがとれます！
> 16:17 - pochi_udon: メモ：
前提
• 動画作成時の基本モーションは固定（元動画のほぼマルパクリ）
• 変化させるのは何を話すのか、多少のモーション、脚本（構成、カット、セリフなど）
分析で評価したいもの
• フックが良かったか？（最初のワードは良かったか？など、パフォーマンスのスワイプ指標などから算出？）
• CTAに繋がったか？（アカウントのフォロワー数が伸びたり、クリック数などから取得？）
-----
cc: <@U09RBQP1J78> 再確認だけど、これで認識はあっているよね？
> 16:28 - 鈴田智仁: 分析で評価したいもの
• フックが良かったか？（最初のワードは良かったか？など、パフォーマンスのスワイプ指標などから算出？）
• CTAに繋がったか？（アカウントのフォロワー数が伸びたり、クリック数などから取得？）
追加して以下の観点も持ちたいです
• 企画の良し悪し（参考動画から分析してシナリオ作るところのプロンプトをブラッシュアップするため）
    ◦ マーケットが良かったのかどうか？（マーケット　例：AI関連）
    ◦ テーマが良かったのかどうか？（具体のテーマ　例：geminiの使い方）
    ◦ 構成が良かったのか（シナリオの流れ）
    ◦ それぞれの構成のセリフが良かったか？（具体のセリフの文章の作り方やセリフの文字数とか）
• 離脱ポイントはどこか？（動画のアナリティクスで離脱箇所がわかったりするんですけどデータがとれれば）
    ◦ 離脱要因は何か→基本モーションは固定だからシナリオ側の改善
• キャラクターデザインはよかったか？　
    ◦ これは動画単体というより全アカウントの傾向からどんなキャラクターがいいかを分析したい
> 17:00 - pochi_udon: 上記全てを内包した動画分析方針作成中...
> 17:23 - pochi_udon: 1回目の結果を共有する：<https://chatgpt.com/s/t_6984537b576c819197763651dd5c18ac>
> 17:59 - pochi_udon: 上記の方針を実際のフロー3構成要素（情報のインプット・AIによる分析・分析レポートの出力）に分解した上で理解しやすくまとめ直してもらっている。
> 18:15 - pochi_udon: &gt; その他のやるべきことの優先順位づけ
駿冴
• 方針決め
• <https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770281980618059?thread_ts=1770041631.565879&amp;cid=C09RBQH0NA2|この方針>のフロー化
トモさん
• 作業中WFの最終調整
-----------------------------
[MVPワークフローの整理]※単純化したもの
• 人間がプラットフォームを適当にスクロールして使えそうな動画の発見
• その動画をトモさんが作成してくれたWFに入れて新しい動画を作成（以下のフローのもの）
&gt; シナリオ側
&gt; 元動画を分析（動画分析プロンプト）→分析結果と、手動でシナリオのテーマを入力→脚本作成（シナリオ作成プロンプト）→脚本から音声を作成
&gt; 
&gt; 動画生成側（プロンプトなし）
&gt; 元動画からモーションを作成→音声データとモーションをリップシンク
• 上記で作成中の分析フローに入れる
<@U09RBQP1J78> 人間介入部分もあるから簡略化すると上記の認識であっているよね？
> 18:30 - 鈴田智仁: 概ねあってる！

&gt; 動画生成側（プロンプトなし）
&gt; 元動画からモーションを作成→音声データとモーションをリップシンク
→ここにもう一つ工程が入って
元動画をモーションごとにカットする
ってのを手動でやってる
今後動画が増えた際にどのモーションが良かったかやどのモーションの組み合わせがいいかなども分析できる様にしたく

それぞれのフローをwebアプリ上では試せてて、n8nからAPI呼んで回るかがまだ試せてない！
大体のワークフローは組めてるから、APIからの出力がうまくいくか調整する形になる

```作業メモ
調整としては、スプシに連携するところがまだできてないから
・動画の分析結果をスプシに保存する
・分析結果のスプシと新規のテーマ（手動で決める）を読み取って新規シナリオを新しいスプシに作る（新規のスプシにセリフと各シーンのモーションデータのリンクを貼る感じにする）
・作ったスプシから動画をつくる

最初手動で行って今後自動化したいこと
・参考動画をモーションごとにカットしてドライブに保存する（フック、ボディ、CTA）
・保存したモーションのデータリンクをスプシに貼る```
> 19:21 - pochi_udon: <https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770281980618059?thread_ts=1770041631.565879&amp;cid=C09RBQH0NA2|これ>に対しての2回目のブラッシュアップ結果：<https://chatgpt.com/s/t_6984619f6098819186205682b67da459>
> 19:33 - pochi_udon: <@U023YG4NDB8> 一応作業開始する前に再度僕がズレてないか確認お願い。この方向性で進めようと思う。
上記のものをさらに具体化・整理して、ネクストアクションに落とし込んだもの。
（意見と提案）あとこれからこのアクションに入るにあたってGPTと話していて感じたこととしては、この分析部分に限っては個人的にClaude Code使って機能を実現した方が良いと心変わりをしてきている。全体のフロー・アーキテクチャを組むのならn8n優勢だけど、そのフローの1部や今後も細かく修正をしていくことを考えた時に、コンテキストを理解しているClaudeに自然言語で指示出しした方が低コストで高アウトプットが期待できると感じたため。
MVP以後にすでにn8n上にあるWFと連携させることを考えた時でも、この機能にAPIを持たせれば良いだけなので（コストは高くない）問題はないと思う。
どう思う？
-> <https://chatgpt.com/s/t_69846e9027748191a563ce2f85c3ad62>
cc: <@U09RBQP1J78>
> 19:34 - 鈴田智仁: 確認する！
> 19:47 - 鈴田智仁: このシートに合わせてスプシとワークフローを調整すれば大丈夫だからすすめてOK

クラウドコードで実現するのは良いと思う
一応、以前エージェント作るのにlanggraphが使えるみたいなのをみてn8nとの違いを聞いてるからこの辺も候補にいれてもいいかも
gptとの会話
<https://chatgpt.com/share/698049d6-aa3c-8004-b32a-52176627c2df>
> 19:59 - pochi_udon: Ty! LangGraph見てみる！
> 20:44 - pochi_udon: メモ :
OpenClawがいいかも？（後々他の事をさせる時があるかもしれない事を踏まえての、足がかりとしての慣れることも出来るので一石二鳥？）
> 22:15 - pochi_udon: 状況整理共有（ここでは簡潔に、詳細はリンク先に。）：
&gt; 今の状況は「制作（分析→脚本→音声→モーション→リップシンク）」のn8nフローはチームがほぼ完成させている一方、あなたの担当は「投稿後のパフォーマンス×KPI×使用プロンプト×シナリオシート」を材料にした *分析・反省・改善提案の生成*。この分析は、実質的に *Input→Analysis→Output の3ステップ*で固定でき、しかも今後ずっと改善し続ける“コア”になる。だから、ノーコードのn8nで無理にやるより、*コードベースとして育てられて、文脈（過去データ）や仕様（スキーマ）を踏まえて改修しやすい形*にしたい。そこで「Claude Codeのようなコーディング支援エージェントを使って、分析パイプラインをコードで実装する方が良いのでは」と感じている。さらに、分析は毎回単発ではなく横断して学習し、分析手法自体も改善していきたいので、*長期記憶（メモリ）レイヤー*をどう作るか（LangGraph / OpenClaw / あるいはDB＋ベクタ検索等）を調べて決めたい。
-&gt; <https://chatgpt.com/s/t_698497b9df7481918b4dc1d21b541ab4>
> 22:36 - Badhan: こう言うのはちょくちょく投げておいて欲しい！
認識揃うし、今の思考状況も把握できるから
> 11:11 - 鈴田智仁: <https://x.com/oikon48/status/2019475142230048999?s=46|https://x.com/oikon48/status/2019475142230048999?s=46>

クラウドコードでこういうのできるらしい
> 11:13 - pochi_udon: 丁度同じもの見てた。
> 11:33 - pochi_udon: <@U023YG4NDB8> がアカウント作成していると思うけど、情報をもらって僕の方からでもアカウントのダッシュボードにアクセスしても大丈夫？実際にダッシュボードに入っていどこからどのようにパフォーマンスデータのCSVデータがエスクポートできるのかの動線を確認したい。
> 11:55 - Badhan: これの4番目のやつは動いてるからログインして大丈夫
<https://docs.google.com/spreadsheets/d/1miRwmWz1t46jEGBTsK51ZsNHfMRhJs4dCOVKi-9zC84/edit?usp=drivesdk|https://docs.google.com/spreadsheets/d/1miRwmWz1t46jEGBTsK51ZsNHfMRhJs4dCOVKi-9zC84/edit?usp=drivesdk>
> 12:38 - pochi_udon: システムアーキテクチャ概要
```┌─────────────────────────────────────────────────────────────────────┐
│                         Human Workflow                               │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   [YouTube Studio]  [TikTok Analytics]  [IG Professional Dashboard] │
│         │                  │                      │                  │
│         ▼                  ▼                      ▼                  │
│   [Export CSV]       [Export CSV]          [Export CSV]             │
│         │                  │                      │                  │
│         └──────────────────┼──────────────────────┘                  │
│                            ▼                                         │
│                   [Upload to Google Drive]                           │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         n8n Workflow                                 │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   [Google Drive Trigger] ──► [Read CSV] ──► [Call GAS Web App]      │
│                                                                      │
│                                   │                                  │
│                                   ▼                                  │
│                         [Receive Analysis]                           │
│                                   │                                  │
│                                   ▼                                  │
│                  [Feed to Video Creation Workflow]                   │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    Google Apps Script (GAS)                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   ┌─────────────┐    ┌─────────────┐    ┌─────────────┐            │
│   │  Code.gs    │    │ CSVParser.gs│    │ Normalizer  │            │
│   │ (Endpoints) │───►│ (Parse CSV) │───►│ (Unify)     │            │
│   └─────────────┘    └─────────────┘    └─────────────┘            │
│                                               │                      │
│                                               ▼                      │
│   ┌─────────────┐    ┌─────────────┐    ┌─────────────┐            │
│   │ SheetWriter │◄───│ LLMAnalyzer │◄───│  Linker.gs  │            │
│   │ (Output)    │    │ (OpenAI)    │    │ (video_uid) │            │
│   └─────────────┘    └─────────────┘    └─────────────┘            │
│         │                  │                                         │
│         ▼                  ▼                                         │
│   [Google Sheets]   [OpenAI API]                                    │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘```
データフロー概要
```[CSV Upload] → [n8n Trigger] → [GAS Web App]
                                     │
                 ┌───────────────────┘
                 ▼
         [CSV Parser] → [Normalizer] → [video_uid Linker]
                                            │
                 ┌──────────────────────────┘
                 ▼
         [KPI Comparison] → [OpenAI Analysis] → [Report Sheets]
                                                      │
                 ┌────────────────────────────────────┘
                 ▼
         [n8n: Feed to Video Creation WF]```
> 15:54 - pochi_udon: <@U09RBQP1J78>
分析スタイルについて、それぞれの動画ごとに3つのプラットフォームのパフォーマンスデータを組み合わせて横断的なものが良いよね？
> 16:04 - 鈴田智仁: 動画の評価をするのにいろんなデータがあった方が動画自体の良し悪しがよりわかる気がするから横断的でいいと思う！
> 16:40 - pochi_udon: 途中経過共有：
ベースラインのやつは<https://docs.google.com/spreadsheets/d/1fI1s_KLcegpiACJYpmpNe9tnQmnZo2o8eHIXNV5SpPg/edit?usp=sharing|ここ>にできた。上記システムアーキテクチャ概要の「Google Apps Script (GAS)」の部分のもの。
シート上にインプット・アウトプットデータが溜まっていって、裏側ではそのデータの分析がコードで行われるという感じ。
シート上に溜まるだけだと人間にとっては分かりにくくなるので、将来的にダッシュボードアプリをフロントに接続することも将来的には検討。
細かい部分まで挙動が把握出来ていないのと、<https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770276500091389?thread_ts=1770041631.565879&cid=C09RBQH0NA2|ここら辺>まで網羅的に分析・まとめられるように、話しながら・理解しながら修正をしている最中。
> 19:28 - pochi_udon: *状況共有：*
AIが分析をするために必要なデータを全て構造化させるためのフォーマットを構築。
-> （出来れば）全てをDrive内にまとめる。※<https://fal.ai/|fal.ai>のAPIから画像を読み込む時にGoogleドメインではエラーが出るため<https://cloudinary.com/|Cloudinary>を用いている。（<https://chatgpt.com/share/6985b558-83f8-8004-ad7c-fbfb49c5c9ae|参考>）
-> 全てのデータに関して実データ以外に、IDとプロパティを持たせて管理シートにまとめる。
-> 管理シートごとにIDを経由してデータの関係性を実現する。
-> マスターシートだけを見れば全ての構想要素が分かるようになる。
------------------------
*分析のアウトプットとして欲しい要素：*
• シナリオ
• モーション（元動画をフック、ボディ、CTAのカテゴリーに分けて、それぞれで複数の種類に細分化される。）
• ~人物画像（プラットフォーム内で運用するアカウントのこと：初期段階ではスコープ外　※複雑化防止）~
※まずはそれぞれのカテゴリー（上部）に関してインベントリーの中からの最適な組み合わせの観点で分析をする。それを行った複数の分析を横断してみたときに、教師なし学習がなされる（と思う）。正解ラベルが付与されていない大量のデータから、AI自身が隠れた構造、パターン、規則性を見つけ出す機械学習の手法。
※1動画=1シートが作成される。<https://docs.google.com/spreadsheets/d/1SPWaPJxYVEl14ykaX-PwCtqLZDnVCZJFcDRxx8Qtp8I/edit?usp=sharing|参考資料>。
------------------------
*補足：*
• 30アカウント動かす。
• 10人キャラクターいる。
• 1キャラクターを3つのプラットフォームで使用し、同じ動画を投稿する。
• 今日（2/6）から4番目のアカウントで1つ動画投稿開始。
• 人間が介入しないといけないやつを*後に*全て自動化。将来的な目標は、動画を入れたらあとは勝手に声->脚本->動画というまで全自動で行えること。

### 23:34 JST - Badhan ([link](https://ceed0105.slack.com/archives/C09RBQH0NA2/p1770042865637789))
メモ
他の人が垢BANくらってる理由を明確にする

> **スレッド (5件):**
> 13:52 - Zach(高橋勇作): こういう対策とかも簡単にプラットフォーム側はやってきそう
<https://x.com/cat_meety/status/2018528387934068790?s=20>
> 14:00 - 鈴田智仁: これ生成した動画を編集ソフトで何も編集せずに書き出すだけで回避できそうですね
> 14:31 - Badhan: 編集ソフトを使うとこの「ウォーターマーク」が作ってことですか？？
AIが勝手に埋め込んでると思ってました
> 15:01 - 鈴田智仁: あ、いや不可視のデータが埋め込まれてるのでそれを再度編集ソフトで書き出し直したら消えるかなと
> 15:01 - 鈴田智仁: 動画データ自体が他の動画になるんで


</details>
