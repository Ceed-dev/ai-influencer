# アルゴリズム精度分析 --- 仮説的中率予測・成長曲線・改善戦略

> **作成日**: 2026-02-16
>
> **対象**: v5.0仮説駆動サイクルにおけるアルゴリズム精度の予測・改善分析
>
> **前提**: [04-agent-design.md](04-agent-design.md)の仮説駆動サイクル設計、[03-database-schema.md](03-database-schema.md)のhypotheses/learningsテーブル設計に基づく
>
> **関連ドキュメント**:
> - [07-kpi-analysis.md](07-kpi-analysis.md) --- KPI達成可能性分析 v3
> - [ALGORITHM-CONTENT-VOLUME-ANALYSIS.md](../ALGORITHM-CONTENT-VOLUME-ANALYSIS.md) --- アルゴリズムとコンテンツ量の関係性分析
> - [02-architecture.md](02-architecture.md) --- v5.0システムアーキテクチャ

## 目次

- [1. エグゼクティブサマリー](#1-エグゼクティブサマリー)
- [2. アルゴリズム精度の定義](#2-アルゴリズム精度の定義)
- [3. 月別精度予測](#3-月別精度予測)
- [4. 精度向上のメカニズム](#4-精度向上のメカニズム)
- [5. 品質スコアの進化](#5-品質スコアの進化)
- [6. pgvectorの貢献](#6-pgvectorの貢献)
- [7. エージェント個別精度分析](#7-エージェント個別精度分析)
- [8. アルゴリズム精度が不十分な場合の対策](#8-アルゴリズム精度が不十分な場合の対策)
- [9. アカウント数・投稿数の十分性分析](#9-アカウント数投稿数の十分性分析)
- [10. 成長曲線のシミュレーション](#10-成長曲線のシミュレーション)
- [11. リスクと限界](#11-リスクと限界)
- [12. 判断ロジック・数式定義](#12-判断ロジック数式定義)
- [13. データ変換ロジック](#13-データ変換ロジック)
- [14. 結論](#14-結論)


## 1. エグゼクティブサマリー

v5.0の核心は**仮説駆動サイクル**である。エージェントが立てた仮説がどの程度「的中」するかが、システム全体のパフォーマンスを決定する。本レポートでは、このアルゴリズムの精度を12ヶ月にわたって予測し、精度向上のメカニズムと改善戦略を分析する。

### 主要な予測

| 指標 | 3ヶ月後（3月） | 6ヶ月後（6月） | 12ヶ月後（12月） |
|---|---|---|---|
| 仮説的中率 | 25〜35% | 70〜82% | 88〜93% |
| 予測誤差 | 45〜65% | 10〜20% | 5〜10% |
| 蓄積知見数 | 30〜60 | 800〜1,500 | 4,000+ |
| コンテンツ品質改善率 | 基準値 | +40〜70% | +80〜150% |
| 月間学習イベント数 | 900〜2,400 | 15,000〜45,000 | 105,000 |

> **注**: v5.0は**コンテンツ単位の学習ループ**を採用する。毎回のコンテンツ制作が学習イベントとなり、即座に分析→知見蓄積→次のコンテンツへ反映される。4月（Phase 3）からLangGraphエージェントが稼働し、日次サイクルではなくコンテンツ完了トリガーで連続的に学習が進行する。6月時点で累計10万件以上の学習イベントが蓄積され、精度は急速に向上する。

### 核心的なインサイト

1. **初期でも「教育された推測」**: 最初の月でも900〜2,400件のコンテンツから学習。的中率25〜35%（LLMの一般知識 + 即座のフィードバック）
2. **2〜3ヶ月で「高速パターン認識」**: 累計1万件以上のデータポイントにより、ニッチ固有のパターンが高い統計的信頼度で浮上する
3. **4〜6ヶ月で「精密予測」**: 累計5万件以上の学習イベントで、コンテンツ×ニッチ×時間帯の組合せ空間が十分にカバーされ、精度70%を突破する
4. **天井は90〜95%**: 1日3,500件以上のデータポイントにより、ノイズを統計的に排除可能。残る5〜10%は予測不能な外部イベント（バイラル偶発性、突発ニュース等）
5. **pgvectorによるクロスニッチ学習が精度80%突破の鍵**: ニッチAでの知見がニッチBに転用されることで、学習速度が2〜3倍に加速し、個別ニッチでは到達できない精度レベルに到達する
6. **per-content分析の二重構造**: 即座の分析（コンテンツ完了→48h以内にメトリクス→verdict判定）+ ベクトル検索による歴史的パターンマッチング。この二重構造がサイクル型の6,000倍の学習速度を実現する
7. **エージェント個別の精度追跡が全体最適化を駆動する**: 各エージェント（リサーチャー、アナリスト、プランナー、戦略エージェント）が自身の精度を自己評価・自己改善し、個々の改善が連鎖的にシステム全体の精度を押し上げる好循環を形成する


## 2. アルゴリズム精度の定義

### 2.1 主要指標の定義

v5.0の「アルゴリズム精度」を以下の4指標で定義する。

#### 仮説的中率 (Hypothesis Accuracy)

```
仮説的中率 = confirmed / (confirmed + rejected)
                     ※ inconclusiveは除外
```

- `confirmed`: 仮説で予測したKPI値を実績が上回った（または許容誤差内に収まった）
- `rejected`: 仮説で予測したKPI値を実績が大幅に下回った
- `inconclusive`: データ不足、外部要因、測定期間不足等でまだ判定できない

> 記録先: `algorithm_performance.hypothesis_accuracy`。判定の閾値・数式はセクション12を参照。

**例**: 仮説「美容ニッチのBefore/After形式は完視聴率75%以上を達成する」
- 実績: 完視聴率78% → **confirmed**
- 実績: 完視聴率52% → **rejected**
- 実績: 投稿後2日でまだデータ不十分 → **inconclusive**

#### 予測誤差 (Prediction Error)

```
予測誤差 = average( |predicted_kpis - actual_kpis| / NULLIF(actual_kpis, 0) )
                    全confirmed/rejected仮説で計算（actual=0の場合はNULL、集計から除外）
```

- 仮説ごとに「予測したKPI値」と「実際のKPI値」の乖離率を計算
- 全仮説の平均乖離率
- 低いほど良い（精度が高い）

**例**: 仮説「このフック形式で3秒離脱率35%以下」
- 予測: 35%、実績: 32% → 誤差 = |35-32|/32 = 9.4%
- 予測: 35%、実績: 58% → 誤差 = |35-58|/58 = 39.7%

#### 学習蓄積速度 (Learning Accumulation Rate)

```
学習蓄積速度 = 新規知見数 / コンテンツ数（1コンテンツあたりの新規知見寄与）
```

- 各コンテンツの制作→計測→分析サイクルで、何件の再利用可能な知見が生成・更新されるか
- 初期はコンテンツ100件あたり3〜5件の新規知見、成熟期はコンテンツ100件あたり1〜2件（既存知見の信頼度更新が中心）
- コンテンツ単位の学習により、日次サイクル型と比較して月間学習イベント数が数千倍になる

#### 改善率 (Improvement Rate)

```
改善率 = (今月の仮説的中率 - 先月の仮説的中率) / 先月の仮説的中率
```

- 月次で的中率がどれだけ改善したか
- 初期は大幅な改善（+30〜50%/月）、成熟期は逓減（+5〜10%/月）

### 2.2 指標間の関係

```
┌──────────────────────────────────────────────────────────┐
│                                                          │
│  仮説的中率 ←─── 蓄積知見数 ←─── 学習蓄積速度            │
│       │              ↑                                   │
│       │              │                                   │
│       └──────→ 改善率 ←── 予測誤差の低下                  │
│                      │                                   │
│                      └──→ コンテンツ品質向上               │
│                           └──→ エンゲージメント向上        │
│                                └──→ インプレッション増加    │
│                                     └──→ KPI達成           │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

> **注**: 上記はシステム全体の指標間関係である。各指標の背後には個々のエージェント（リサーチャー、アナリスト、プランナー、戦略エージェント）の個別精度があり、エージェントごとの自己改善がこれらの指標を駆動する。詳細はセクション7「エージェント個別精度分析」を参照。

### 2.3 データベースでの追跡

`hypotheses`テーブルの主要カラムと精度計算の関係:

| カラム | 型 | 精度指標との関係 |
|---|---|---|
| `verdict` | enum('pending','confirmed','rejected','inconclusive') | 的中率の分母・分子 |
| `predicted_kpis` | jsonb | 予測誤差の計算元 |
| `actual_kpis` | jsonb | 予測誤差の計算元 |
| `confidence` | float(0.0〜1.0) | エージェントの事前確信度 |
| `category` | text | カテゴリ別精度分析 |
| `created_at` / `updated_at` | timestamp | 時系列分析 |

`learnings`テーブルの主要カラムと蓄積指標の関係:

| カラム | 型 | 蓄積指標との関係 |
|---|---|---|
| `category` | enum('content','timing','audience','platform','niche') | 知見の分類 |
| `applicable_niches` | VARCHAR(50)[] | 適用可能なニッチ |
| `applicable_platforms` | VARCHAR(20)[] | 適用可能なプラットフォーム |
| `confidence` | NUMERIC(3,2) | 知見の信頼度（再現性） |
| `evidence_count` | integer | 知見を裏付けるデータポイント数 |
| `embedding` | vector(1536) | pgvectorでの類似検索用 |


## 3. 月別精度予測

### 3.1 予測テーブル

v5.0の開発スケジュール（Phase 1〜5）と連動した月別精度予測。v5.0では**コンテンツ単位の学習ループ**を採用し、毎回のコンテンツ制作が独立した学習イベントとなる:

| 月 | Phase | 月間コンテンツ数 | 仮説数(累計) | 的中率(予測) | 予測誤差 | 蓄積知見数 | 備考 |
|---|---|---|---|---|---|---|---|
| 3月 (Phase 2完了) | 初期テスト | 900〜2,400 | 50〜150 | 25〜35% | 45〜65% | 30〜60 | DB稼働開始。コンテンツ単位学習で初月から大量データ蓄積 |
| 4月 (Phase 3) | 学習開始 | 3,000〜6,000 | 200〜500 | 40〜55% | 25〜40% | 120〜250 | LangGraphエージェント初稼働。per-content分析で高速パターン認識 |
| 5月 (Phase 4) | 自律運用 | 9,000〜24,000 | 600〜1,500 | 55〜70% | 15〜25% | 350〜700 | 全エージェント稼働。クロスニッチ学習が本格化 |
| 6月 (Phase 5) | 最適化 | 15,000〜45,000 | 1,500〜4,000 | 70〜82% | 10〜20% | 800〜1,500 | ダッシュボード + 人間介入。累計5万件以上の学習イベントで精度急上昇 |
| 9月 | 成長期 | 60,000〜90,000 | 5,000〜10,000 | 82〜88% | 6〜12% | 2,500〜3,500 | 統計的パワーによりノイズ排除。レアパターンも検出可能に |
| 12月 | 成熟期 | 105,000 | 15,000+ | 88〜93% | 5〜10% | 4,000+ | 天井付近。エッジケース最適化。予測不能な外部イベントのみが誤差源 |

### 3.2 学習イベント数の根拠

v5.0のper-content学習モデルでは、各コンテンツの制作→投稿→計測→分析が1つの学習イベントとなる:

| Phase | 稼働アカウント数 | 投稿数/アカウント/月 | 月間学習イベント数 | 日間学習イベント数 |
|---|---|---|---|---|
| Phase 2 (3月) | 30〜80 | 30 | 900〜2,400 | 30〜80 |
| Phase 3 (4月) | 100〜200 | 30 | 3,000〜6,000 | 100〜200 |
| Phase 4 (5月) | 300〜800 | 30 | 9,000〜24,000 | 300〜800 |
| Phase 5 (6月) | 500〜1,500 | 30 | 15,000〜45,000 | 500〜1,500 |
| 成熟期 (9〜12月) | 2,000〜3,500 | 30 | 60,000〜105,000 | 2,000〜3,500 |

> **日次サイクル型との比較**: 日次サイクルでは月間10〜15サイクル（＝学習イベント）だった。per-contentモデルでは6月時点で月間15,000〜45,000イベントとなり、**1,000〜3,000倍**の学習速度を実現する。この圧倒的なデータ量が90%+精度の基盤となる。

### 3.3 的中率25〜35%（初期）の意味

「初月から25〜35%を達成できる」理由:

1. **エージェントは一般知識を持つ**: Claude Sonnet 4.5はソーシャルメディアマーケティングの一般的な知識を持つ。最初の仮説は「一般論の適用」であり、ゼロからの推測ではない
2. **リサーチャーの市場調査**: リサーチャーエージェントがWebSearchで収集した最新のトレンド・競合情報が仮説の根拠になる
3. **per-content即時フィードバック**: 初月でも900〜2,400件のコンテンツから即座に学習。月後半にはマイクロサイクル分析結果が蓄積し始め、初月内でもパターン認識が開始される
4. **25〜35%は「教育を受けた推測 + 即時学習」**: LLMの一般知識ベースライン（15〜20%）に加え、per-contentマイクロサイクルが初月後半から+10〜15%の寄与を開始する

### 3.4 的中率90〜95%が到達可能で、天井となる理由

per-content学習モデルにより、従来の日次サイクル型（天井65〜70%）を大幅に超える精度が実現可能になる:

#### 90%+が可能になる要因

| 要因 | メカニズム | 精度への寄与 |
|---|---|---|
| **圧倒的データ量** | 日間3,500件以上のデータポイントにより、統計的にノイズを排除 | +15〜20% (vs 日次サイクル) |
| **即時フィードバック** | コンテンツ完了→48h以内に分析。パターン変化を数時間で検知 | +5〜10% |
| **二重分析構造** | 即座の定量分析 + pgvectorによる歴史的パターンマッチング | +5〜8% |
| **クロスニッチ転用** | 10+ニッチの並列学習により、パターンの汎化性が向上 | +5〜8% |

#### 残る5〜10%の誤差源（制御不能な変数）

| 制御不能な変数 | 影響 | per-contentモデルでの緩和 |
|---|---|---|
| プラットフォームのアルゴリズム変更 | 突然の配信ロジック変更でパフォーマンスが急変 | 日間3,500件のデータで変更を数時間〜1日で検知・適応（日次サイクルでは数日〜数週間） |
| トレンドの急変 | 昨日バズったフォーマットが今日は飽きられる | 市場リサーチを2〜4時間ごとに実行し、トレンド変化を即座にキャッチ |
| 競合の動き | 同ニッチの競合が同時に同じ戦略を採用 | 競合監視をリサーチャーの常時タスクに組み込み |
| 外部イベント | ニュース、季節、社会的イベントが視聴行動に影響 | 外部イベントデータをmarket_intelに即時反映 |
| 初期テストプールの偶然性 | 同じコンテンツでも最初に表示されるユーザーで結果が変わる | 大量データにより偶然性の影響を統計的に平滑化 |

> **90%+到達の必要条件**: ①月間1,000件以上のコンテンツ制作（Phase 4以降で達成）、②5ニッチ以上の並列運用、③市場リサーチの2〜4時間更新、④3ヶ月以上の累積学習データ、⑤計測パイプラインの収集率95%以上


## 4. 精度向上のメカニズム

### 4.1 フェーズ別の学習メカニズム

#### Phase A: 高速ベースライン構築（1〜2ヶ月目）

```
コンテンツ制作（900〜2,400件/月）
         ↓
各コンテンツの即時分析（投稿後48h以内にメトリクス収集→verdict判定）
         ↓
仮説: 一般的なSNSマーケティング知識 + リサーチャーの最新データ + 即時フィードバック
         ↓
結果: 25〜35%が的中（大量データにより初月からパターンの兆候を検出）
         ↓
知見: 「このニッチでは〇〇が重要」（中確信度 — 数百件のデータに基づく）
```

このフェーズの特徴:
- 月間900〜2,400件のコンテンツがそれぞれ学習イベントとなる
- 日次サイクル型の100倍以上のデータ収集速度
- 統計的有意性が早期に得られ、「たまたま」と「パターン」の区別が1ヶ月目から可能

#### Phase B: 高速パターン認識（3〜4ヶ月目）

```
コンテンツ制作（3,000〜6,000件/月、累計6,000〜12,000件）
         ↓
仮説: 蓄積知見（120〜250件）+ ニッチ固有パターン + リサーチデータ + ベクトル類似検索
         ↓
結果: 40〜55%が的中（統計的に裏付けられたパターンに基づく仮説の精度が急上昇）
         ↓
知見: 高確信度のアクション可能な知見（「フック3秒以内に質問形式 = 離脱率-30%」、evidence_count: 50+）
```

このフェーズの特徴:
- 累計6,000件以上のデータでニッチ別パターンが統計的に確定する
- pgvectorでの類似仮説検索が有効に機能し始める
- 仮説の粒度が急速に細かくなる（「美容ニッチの20代女性向け×TikTok×朝投稿」レベル）

#### Phase C: 精密予測（5〜6ヶ月目）

```
コンテンツ制作（9,000〜45,000件/月、累計30,000〜80,000件）
         ↓
仮説: 高確信度の蓄積知見 + クロスニッチの類似パターン + 時系列トレンド + 二重分析
         ↓
結果: 55〜82%が的中（複合仮説 + 大量データの統計的パワーにより精度が70%を突破）
         ↓
知見: 複合的な高精度戦略（「美容ニッチ + Before/After + 15秒 + 朝7時投稿 = 完視聴率78%±5%」）
```

このフェーズの特徴:
- 累計数万件のデータにより、多変量の複合パターンが統計的に検証可能
- pgvectorによるクロスニッチ学習が本格化し、精度の壁を突破
- コンテンツ品質スコアが目に見えて向上（平均6.5→7.5）

#### Phase D: 高精度運用（7ヶ月目以降）

```
コンテンツ制作（60,000〜105,000件/月、累計200,000件以上）
         ↓
仮説: 精緻な予測モデル + 外部変数の即時組み込み + リアルタイムトレンド検知
         ↓
結果: 82〜93%が的中（残る誤差は予測不能な外部イベントのみ）
         ↓
知見: 防御的知見（「アルゴリズム変更の兆候を日間データから数時間で検知」）+ 精密予測モデル
```

このフェーズの特徴:
- 改善率は逓減するが、高い水準で安定（月+1〜3%程度）
- 日間3,500件のデータにより、プラットフォームアルゴリズム変更を即座に検知・適応
- 主な改善はエッジケース（レアなニッチ×プラットフォーム組合せ）への対応と予測の校正

### 4.2 学習の複利効果

```
知見の蓄積と仮説精度の関係（per-contentモデル）:

的中率(%)
  95 |                                                    ────── ← 天井 (90-95%)
     |                                               ───/
  90 |                                          ────/
     |                                     ────/
  85 |                                ────/
     |                           ────/
  80 |                      ────/
     |                 ────/
  75 |            ────/
     |        ───/
  70 |     ──/
     |   ─/
  65 |  /                                                 ← per-content学習の加速ゾーン
     | /
  60 |/
     |
  50 |──
     |  \
  40 |   ──
     |     \
  30 |      ──
     |
  20 |
   0 +────────┬────────┬────────┬────────┬────────┬────────
     0        100      500     1,000    2,000    4,000+   知見数

  ↑ S字曲線: per-contentモデルではS字の立ち上がりが大幅に早期化
```

この曲線がS字になる理由:
- **初期（0〜100知見）**: 月間900〜2,400件のコンテンツデータにより、知見の蓄積が高速。日次サイクル型の数ヶ月分を1ヶ月で達成
- **加速期（100〜1,000知見）**: 知見同士の相互参照 + pgvectorクロスニッチ転用で急上昇。per-contentの即時フィードバックにより知見の更新サイクルが数時間単位
- **精密化期（1,000〜2,000知見）**: 統計的パワーにより精度が80%を突破。ノイズと真のパターンの区別が確実に
- **天井期（2,000知見以上）**: 新規知見の限界効用が逓減。改善は既存知見の校正とエッジケース対応が中心

### 4.3 仮説カテゴリ別の精度推移

仮説のカテゴリによって、学習速度と天井が異なる:

| カテゴリ | 初期的中率 | 6ヶ月後的中率 | 天井 | 学習速度 |
|---|---|---|---|---|
| **フック形式** | 35% | 85% | 95% | 最速（A/Bテストが容易 + 大量データで即座に判定） |
| **投稿時間** | 40% | 88% | 95% | 最速（定量データが明確 + 時間帯別の統計が日間数百件で安定） |
| **コンテンツ長** | 30% | 78% | 92% | 速い（ニッチ依存だがper-contentの大量データで収束が早い） |
| **ハッシュタグ** | 25% | 72% | 88% | 速い（トレンド変動が大きいが、2〜4時間ごとのリサーチで追従） |
| **ナラティブ構造** | 20% | 65% | 85% | 中程度（主観的だがメトリクスとの相関分析で客観化可能） |
| **ニッチ選定** | 25% | 60% | 80% | 中程度（市場変動が大きいが、クロスニッチ学習で適応速度向上） |
| **プラットフォーム戦略** | 30% | 68% | 85% | 中程度（アルゴリズム変更の影響があるが日間データで即時検知） |

#### 仮説カテゴリの日英マッピング

ダッシュボード表示（日本語）と DB 保存値（英語 `hypotheses.category`）の対応:

| 日本語（表示） | 英語（DB category） |
|---|---|
| フック形式 | `content_format` |
| 投稿時間 | `timing` |
| ニッチ | `niche` |
| ターゲット層 | `audience` |
| プラットフォーム特性 | `platform_specific` |
| ナラティブ構造 | `content_format` |

> **注**: 「フック形式」と「ナラティブ構造」は同じ `content_format` カテゴリに分類される。DB上はサブカテゴリで区別（`hypotheses.metadata` JSONB の `subcategory` フィールド）。


## 5. 品質スコアの進化

### 5.1 コンテンツ品質メトリクス

v5.0の品質評価は以下のメトリクスで構成される:

| メトリクス | 重み | 測定方法 | 目標値 |
|---|---|---|---|
| **完視聴率** | 35%（system_settings: `QUALITY_WEIGHT_COMPLETION`、デフォルト: 0.35） | プラットフォームAnalytics | 70%以上 |
| **エンゲージメント率** | 25%（system_settings: `QUALITY_WEIGHT_ENGAGEMENT`、デフォルト: 0.25） | (いいね+コメント+シェア)/Imp | 3%以上 |
| **シェア率** | 20%（system_settings: `QUALITY_WEIGHT_SHARE`、デフォルト: 0.20） | シェア数/Imp | 0.5%以上 |
| **3秒離脱率** | 15%（system_settings: `QUALITY_WEIGHT_RETENTION`、デフォルト: 0.15） | Analytics | 40%以下 |
| **コメント感情** | 5%（system_settings: `QUALITY_WEIGHT_SENTIMENT`、デフォルト: 0.05） | NLP分析 | ポジティブ60%以上 |

> 品質スコア算出式: `quality_score = Σ(weight_i × normalized_metric_i)` where `normalized_metric = min(1.0, actual / platform_niche_median)`。各メトリクスのスケーリング関数と詳細はセクション12.5を参照。

### 5.2 コンポーネント別スコアリング

各コンテンツのコンポーネント（シナリオ、モーション、音声、フック、CTA等）に個別のパフォーマンススコアが付与される:

```
┌──────────────────────────────────────────────────────────┐
│                    コンテンツ品質スコア                     │
│                                                          │
│  ┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐        │
│  │ フック   │  │ 本編    │  │  CTA   │  │ 音声    │        │
│  │ Score:8 │  │ Score:6 │  │ Score:7 │  │ Score:9 │        │
│  └────┬───┘  └────┬───┘  └────┬───┘  └────┬───┘        │
│       │           │           │           │              │
│       └───────────┼───────────┼───────────┘              │
│                   ▼                                      │
│           加重平均スコア: 7.2/10                           │
│                   │                                      │
│  ┌────────────────┼────────────────┐                     │
│  ▼                ▼                ▼                     │
│ Score >= 7:     Score 4-6:       Score < 4:              │
│ 積極活用       改善対象         使用停止                   │
│ (replicate)   (optimize)      (deprecate)               │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### 5.3 品質スコアの月別進化予測

| 月 | 平均品質スコア | 上位25%スコア | スコア7以上の割合 | スコア4以下の割合 |
|---|---|---|---|---|
| 3月（初期） | 4.8 | 6.2 | 18% | 25% |
| 4月 | 5.8 | 7.2 | 35% | 15% |
| 5月 | 6.8 | 7.8 | 50% | 8% |
| 6月 | 7.5 | 8.5 | 68% | 3% |
| 9月 | 8.2 | 9.0 | 82% | 1% |
| 12月 | 8.6 | 9.3 | 90% | <1% |

### 5.4 低スコアコンポーネントの自動淘汰

```
品質改善のフィードバックループ:

    コンポーネント使用
         │
    パフォーマンス計測
         │
    スコア更新
         │
    ┌────┴────┐
    │         │
  高スコア  低スコア
    │         │
  優先使用  使用停止
    │         │
  パターン  代替生成
  の横展開   │
    │        └──→ 新コンポーネントで再試行
    └──→ 成功パターンの蓄積
```

**具体例**:
- フックA（質問形式）: 完視聴率78% → スコア8 → 類似フックを生成して横展開
- フックB（衝撃事実形式）: 完視聴率42% → スコア3 → 使用停止 → 代替フック生成
- CTA C（URL誘導型）: エンゲージメント率1.2% → スコア4 → 改善対象 → 表現を変えて再テスト


## 6. pgvectorの貢献

### 6.1 pgvectorの役割

v5.0では、仮説と知見にembeddingベクトル（1536次元）を付与し、類似検索を可能にする。これにより3つの重要な機能が実現される。

### 6.2 類似仮説検索

**ユースケース**: 「この仮説と似た過去の仮説の結果は？」

```sql
-- 新しい仮説のembeddingに最も近い過去の仮説を検索
SELECT h.statement, h.verdict, h.actual_kpis, h.confidence
FROM hypotheses h
WHERE h.verdict IN ('confirmed', 'rejected')
ORDER BY h.embedding <=> $new_hypothesis_embedding
LIMIT 5;
```

**効果**:
- 新しい仮説を立てる前に、類似の仮説が過去に成功/失敗しているかを確認
- 的中率の低い仮説カテゴリを事前に回避
- エージェントの仮説立案の質を直接的に向上させる

**例**:

```
新仮説: 「フィットネスニッチでBefore/After 15秒動画は完視聴率75%を達成する」

類似過去仮説:
1. 「美容ニッチでBefore/After 15秒動画は完視聴率75%を達成する」→ confirmed (実績: 78%)
2. 「ダイエットニッチでBefore/After 30秒動画は完視聴率70%を達成する」→ rejected (実績: 48%)
3. 「フィットネスニッチでチュートリアル60秒動画は完視聴率65%を達成する」→ confirmed (実績: 67%)

→ Before/Afterは効果的だが、30秒だと長すぎる。15秒が最適。フィットネスも美容と類似パターンの可能性が高い。
→ 予測: confirmed（信頼度 0.7）
```

### 6.3 類似知見検索

**ユースケース**: 「このニッチで使える知見は？」

```sql
-- 特定ニッチのembeddingに近い知見を検索
SELECT l.insight, l.applicable_niches, l.confidence, l.evidence_count
FROM learnings l
WHERE l.confidence > 0.5
ORDER BY l.embedding <=> $niche_embedding
LIMIT 10;
```

**効果**:
- プランナーエージェントがコンテンツ計画を立てる際に、関連する知見を自動的に参照
- ニッチを横断した知見の転用（後述）
- 新しいニッチに参入する際の「コールドスタート問題」を緩和

### 6.4 クロスニッチ知見転用

**ユースケース**: 「美容ニッチで成功したパターンをフィットネスにも適用」

```
美容ニッチの知見:
  「Before/After形式のフック + 15秒 + 朝7時投稿 → 完視聴率78%」
       ↓
  pgvector類似検索: フィットネスニッチとの類似度 = 0.82
       ↓
  フィットネスニッチに適用:
  「Before/After形式のフック + 15秒 + 朝7時投稿 → 完視聴率???」
       ↓
  結果: 完視聴率72% → confirmed（類似度の高さに比例して的中率が高い）
```

### 6.5 クロスニッチ学習の効果

per-contentモデルの6ヶ月時点（累計5万件以上のデータ）でのクロスニッチ効果:

| ニッチ数 | pgvectorなし(的中率) | pgvectorあり(的中率) | 改善率 |
|---|---|---|---|
| 1ニッチ | 68% | 68% | 0%（基準） |
| 3ニッチ | 68% | 74% | +9% |
| 5ニッチ | 68% | 78% | +15% |
| 10ニッチ | 68% | 84% | +24% |

ニッチが増えるほどクロスニッチ学習の効果が大きくなる。per-contentモデルでは各ニッチから日間数百件のデータが蓄積されるため、クロスニッチのパターンマッチングが統計的に強固になり、天井突破の鍵となる。

### 6.6 pgvectorの限界

| 限界 | 影響 | 緩和策 |
|---|---|---|
| embedding品質はLLMに依存 | 類似度計算が不正確になる可能性 | text-embedding-3-small使用（[01-tech-stack.md](01-tech-stack.md)参照）、定期的な再embedding |
| ニッチ間の「見かけの類似」 | 表面的に似ているが本質が異なる知見の誤適用 | confidenceによるフィルタリング、人間レビュー |
| ベクトル空間の偏り | 特定ニッチの知見が過剰に参照される | 正規化、多様性スコアの導入 |


## 7. エージェント個別精度分析

システム全体の仮説的中率は、各エージェントの個別精度の**合成結果**である。v5.0では各エージェントが自己反省（self-reflection）を行い、自身の精度を追跡・改善することで、システム全体の最適化を実現する。

### 7.1 エージェント別精度指標の定義

各エージェントの役割に応じた「精度」の定義:

| エージェント | 主要指標 | 計算方法 | 成熟時目標 |
|---|---|---|---|
| **リサーチャー** | 調査精度 (Research Accuracy) | アナリストが「有用」「実行可能」と評価した`market_intel`の割合 | 90%以上 |
| **アナリスト** | 分析品質 (Analysis Quality) | 分析結果が確認済み仮説（`confirmed`）につながった割合 | 85%以上 |
| **プランナー** | 企画成功率 (Planning Success Rate) | 企画したコンテンツが品質スコア7以上を達成した割合 | 80%以上 |
| **戦略エージェント(社長)** | 戦略的中率 (Strategy Accuracy) | 戦略的決定がクラスター成長につながった割合 | 82%以上 |
| **ツールスペシャリスト** | レシピ推奨精度 (Recipe Accuracy) | 推奨レシピが品質スコア7以上を達成した割合 | 88%以上 |
| **データキュレーター** | キュレーション品質 (Curation Quality) | 自動生成コンポーネントがプランナーに採用された割合 | 82%以上 |

#### 各指標の詳細

**調査精度（リサーチャー）**

```
調査精度 = useful_or_actionable_intel / total_intel_delivered
```

- リサーチャーが収集した`market_intel`を、アナリストが後続の分析で「参考になった」「仮説の根拠に使用した」と判定した割合
- 判定基準: アナリストの分析レポートで引用された`market_intel`のID数 / リサーチャーが提出した`market_intel`の総数
- 初期は「広く浅く」収集するため精度は低いが、フィードバックにより「深く鋭く」に進化する

**分析品質（アナリスト）**

```
分析品質 = analyses_leading_to_confirmed / total_analyses_completed
```

- アナリストが提出した分析のうち、そこから生成された仮説が`confirmed`ステータスに到達した割合
- `rejected`や`inconclusive`に終わった仮説の元となった分析は「品質が低かった」と評価される
- ただし、`rejected`であっても価値のある知見が得られた場合は部分的に評価する

**企画成功率（プランナー）**

```
企画成功率 = content_with_score_gte_7 / total_content_planned
```

- プランナーが企画・指示したコンテンツの品質スコア（10点満点）が7以上を達成した割合
- 品質スコアは完視聴率・エンゲージメント率・シェア率等の加重平均（セクション5参照）
- 仮説に基づかない「探索的」コンテンツは別枠で評価する

**戦略的中率（戦略エージェント）**

```
戦略的中率 = strategic_decisions_leading_to_growth / total_strategic_decisions
```

- 戦略エージェントのサイクル方針決定（ニッチ配分、リソース配分、注力領域の選定等）が、担当クラスターの成長に寄与した割合
- 「成長」の定義: 月間インプレッション前月比+10%以上、またはフォロワー数前月比+5%以上
- フィードバックループが最も長い（決定→実行→計測→評価に2〜4週間）

**レシピ推奨精度（ツールスペシャリスト）**

```
レシピ推奨精度 = recipes_with_score_gte_7 / total_recipes_recommended
```

- ツールスペシャリストが推奨した制作レシピ（ツール組み合わせ・パラメータ設定）に基づいて制作されたコンテンツの品質スコアが7以上を達成した割合
- `tool_catalog`の知識更新頻度と、推奨精度の相関を追跡する
- 新ツールの登場直後は精度が一時的に低下し、学習データの蓄積により回復する

**キュレーション品質（データキュレーター）**

```
キュレーション品質 = adopted_components / total_components_generated
```

- データキュレーターが自動生成したコンポーネント（シナリオ要素・テンプレート等）のうち、プランナーが実際にコンテンツ企画で採用した割合
- 重複チェック・品質判定の精度も副次指標として追跡する
- リサーチャーの市場データ品質に依存するため、リサーチャーの精度向上と連動して改善する

### 7.2 エージェント別成長曲線

各エージェントの精度は異なる速度で向上する。フィードバックループの長さと評価の客観性が学習速度を決定する。

```
精度(%)
  95 |                                                         ● リサーチャー (92%)
     |                                                    ●──/
  90 |                                               ●───/    ● ツールスペシャリスト (90%)
     |                                          ●───/    ●──/
  85 |                                     ●───/    ●──/      ● アナリスト (87%)
     |                                ●──/    ●──/       ●──/
  80 |                           ●──/    ●──/       ●──/      ● 戦略/キュレーター (84%)
     |                      ●──/    ●──/       ●──/      ●──/ ● プランナー (82%)
  75 |                 ●──/    ●──/       ●──/      ●──/
     |            ●──/    ●──/       ●──/      ●──/
  70 |       ●──/    ●──/       ●──/      ●──/
     |  ●──/    ●──/       ●──/      ●──/
  65 | /   ●──/       ●──/      ●──/
     |    /       ●──/      ●──/
  60 |           /      ●──/
     |      ●──/   ●──/
  55 |     /      /
     |    /  ●──/
  50 |●──/  /
     |     /
  45 |●──/
     |
  40 |●
     |
  30 |● アナリスト/戦略/キュレーター
  25 |● プランナー
   0 +─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────
     3月    4月    5月    6月    7月    8月    9月   10月   11月   12月
```

#### 月別エージェント精度予測テーブル

| 月 | リサーチャー | アナリスト | プランナー | 戦略エージェント | ツールスペシャリスト | データキュレーター | 備考 |
|---|---|---|---|---|---|---|---|
| 3月 | 50% | 30% | 25% | 30% | 40% | 30% | 全エージェント初期段階。月間900〜2,400件のper-contentデータで高速学習開始 |
| 4月 | 62% | 45% | 38% | 42% | 55% | 45% | リサーチャーが最速で改善。月間3,000〜6,000件のデータ |
| 5月 | 72% | 58% | 52% | 55% | 68% | 58% | アナリストのデータ蓄積が本格化。クロスニッチ学習開始 |
| 6月 | 80% | 68% | 62% | 65% | 78% | 68% | プランナーが品質パターンを学習。累計5万件以上のデータ |
| 9月 | 88% | 80% | 75% | 78% | 86% | 78% | 全エージェントが高精度に到達。日間2,000+件のフィードバック |
| 12月 | 92% | 87% | 82% | 84% | 90% | 84% | 天井付近。per-content学習の飽和域だが高精度を維持 |

#### 学習速度が異なる理由

| エージェント | 学習速度 | 理由 |
|---|---|---|
| **リサーチャー** | 最速 | フィードバックが直接的（アナリストの「使った/使わなかった」が即座に判明）。データは客観的 |
| **アナリスト** | 速い | 仮説のconfirmed/rejectedが数日〜数週間で判明。定量データに基づく改善が可能 |
| **戦略エージェント** | 中程度 | 戦略決定→結果の因果関係が複雑。クラスター成長には複数要因が関与 |
| **プランナー** | 遅い | コンテンツ品質はフック・本編・CTA・音声等の複合要素。試行錯誤の変数が多い |
| **ツールスペシャリスト** | 速い | ツール特性は客観的データ（成功率・品質スコア）で測定可能。`tool_catalog`の蓄積が直接改善に反映 |
| **データキュレーター** | 中程度 | コンポーネント採用率は明確だが、リサーチャーの入力品質に依存。構造化ルールの調整には試行が必要 |

### 7.3 個別最適化からシステム全体最適化への波及

各エージェントの精度向上は孤立せず、**好循環（Virtuous Cycle）**を形成してシステム全体の精度を押し上げる。

```
┌──────────────────────────────────────────────────────────────────┐
│                                                                  │
│              エージェント精度の好循環モデル                          │
│                                                                  │
│          ┌──────────────────┐                                    │
│          │  リサーチャー      │                                    │
│          │  調査精度 向上     │                                    │
│          └────────┬─────────┘                                    │
│                   │ より質の高い市場データ                          │
│                   ▼                                              │
│          ┌──────────────────┐                                    │
│          │  アナリスト        │                                    │
│          │  分析品質 向上     │                                    │
│          └────────┬─────────┘                                    │
│                   │ より正確な知見・仮説検証                        │
│                   ▼                                              │
│          ┌──────────────────┐                                    │
│          │  プランナー        │                                    │
│          │  企画成功率 向上   │                                    │
│          └────────┬─────────┘                                    │
│                   │ より高品質なコンテンツ                          │
│                   ▼                                              │
│          ┌──────────────────┐                                    │
│          │  コンテンツ成果     │                                    │
│          │  メトリクス向上     │                                    │
│          └────────┬─────────┘                                    │
│                   │ より豊富で正確なパフォーマンスデータ              │
│                   ▼                                              │
│          ┌──────────────────┐                                    │
│          │ 戦略エージェント    │                                    │
│          │ 戦略的中率 向上    │                                    │
│          └────────┬─────────┘                                    │
│                   │ より的確なサイクル方針・リソース配分              │
│                   │                                              │
│                   └──────────────→ リサーチャーへ                 │
│                     （調査方針の精緻化・重点領域の指示）              │
│                                                                  │
│  ★ 1つのエージェントの改善が、次のエージェントの入力品質を           │
│    向上させ、サイクル全体の精度が加速度的に改善される                 │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

#### 波及効果の定量モデル

1エージェントの精度が10%向上した場合の、下流エージェントへの波及効果:

| 改善元 | 直接的な影響先 | 波及率 | 波及の具体例 |
|---|---|---|---|
| リサーチャー +10% | アナリスト | +5〜7% | 質の高い市場データ → アナリストの仮説精度が向上 |
| アナリスト +10% | プランナー | +4〜6% | 正確な知見 → プランナーの企画精度が向上 |
| プランナー +10% | コンテンツ成果 | +6〜8% | 高品質コンテンツ → メトリクスが改善 |
| 戦略エージェント +10% | リサーチャー | +3〜5% | 的確な方針 → リサーチャーの調査対象が最適化 |

```
波及効果のシミュレーション:

  リサーチャー +10% → アナリスト +6% → プランナー +4% → 成果 +5%
                                                        ↓
  リサーチャー +3% ← 戦略エージェント +2% ← 成果データ改善 ←┘

  → 1サイクルでシステム全体: 約+5〜8%の精度向上
  → 2サイクル後の累積効果: 約+8〜15%の精度向上（複利効果）
```

### 7.4 自己反省（Self-Reflection）の精度向上への影響

v5.0の各エージェントは、タスク実行後に**自己反省**を行い、自身のパフォーマンスを評価・改善する。これが精度向上速度に決定的な差を生む。

#### 自己反省ありとなしの比較

```
精度(%)
  95 |                                                      ── ← 自己反省あり (per-content)
  90 |                                                 ────/     (2〜3倍速い改善)
  85 |                                            ────/
  80 |                                       ────/
  75 |                                  ────/
  70 |                             ────/
  65 |                        ────/                    ── ← 自己反省なし (per-content)
  60 |                   ────/                    ────/     (外部フィードバックのみ)
  55 |              ────/                    ────/
  50 |         ────/                    ────/
  45 |    ────/                    ────/
  40 |───/                   ────/                     --- ← 日次サイクル型 + 自己反省あり
  35 |                  ────/                     ────/     (旧設計の天井 65-70%)
  30 |●            ────/                     ────/
  25 |        ────/                      ───/
  20 |   ────/                      ────/
  15 |──/                      ────/
  10 |                    ────/
   0 +─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────
     3月    4月    5月    6月    7月    8月    9月   10月   11月   12月

  per-content + 自己反省: 12ヶ月で90%+ (天井 90-95%)
  per-content のみ: 12ヶ月で65-70% (自己反省なしの限界)
  日次サイクル + 自己反省: 12ヶ月で65-70% (旧設計の天井)
```

#### 自己反省のメカニズム

| 段階 | 自己反省なし | 自己反省あり |
|---|---|---|
| **誤り検知** | 外部メトリクスが判明するまで気づかない（数日〜数週間の遅延） | タスク完了直後に「この判断は適切だったか」を自己評価 |
| **原因分析** | 「結果が悪い」のみ。原因は不明確 | 「なぜこの判断をしたか」「どの前提が誤りだったか」を自己分析 |
| **改善策生成** | 次サイクルで同じ失敗を繰り返す可能性 | 自己生成した改善策を次タスクに即座に適用 |
| **学習速度** | サイクル単位（数日〜数週間） | タスク単位（数分〜数時間） |

#### エージェント別の自己反省内容

| エージェント | 自己反省の問い | 改善アクション例 |
|---|---|---|
| **リサーチャー** | 「収集した情報のうち、アナリストに使われなかったものは何か？ なぜ不要だったか？」 | 収集ソースの優先順位を調整。不要だったカテゴリの情報収集頻度を下げる |
| **アナリスト** | 「分析結果から生成した仮説がrejectedになった。分析のどの前提が誤りだったか？」 | 分析に使用するメトリクスの重み付けを変更。外れ値の扱いを見直す |
| **プランナー** | 「品質スコアが低かったコンテンツは何が足りなかったか？ 知見の適用方法が間違っていたか？」 | コンテンツ構成の変数（尺、フック形式、CTA等）の組み合わせパターンを見直す |
| **戦略エージェント** | 「今サイクルのリソース配分は最適だったか？ 注力すべきニッチを見誤っていないか？」 | ニッチ別ROIの再計算。次サイクルの配分比率を調整 |
| **ツールスペシャリスト** | 「推奨したレシピで品質スコアが低かったケースはどのツール組み合わせか？ パラメータ設定に改善余地があったか？」 | `tool_catalog`の特性データ更新。低スコアのツール組み合わせパターンの重み調整 |
| **データキュレーター** | 「自動生成したコンポーネントのうち、プランナーに不採用だったものの共通点は何か？ 構造化ルールに問題があったか？」 | 重複判定の閾値調整。コンポーネント分類ルールの見直し |

### 7.5 エージェント個別の学習飽和分析

各エージェントには役割の複雑さに応じた「精度の天井（ceiling）」が存在する。

```
精度の天井(%) — per-contentモデル
  95 |  ┌──────────────────────────────────────────────────────────┐
     |  │  ████████████████████████████████████████  リサーチャー    │
  92 |  │  ● データが客観的 + per-contentの大量フィードバックで収束 │
     |  │                                                          │
  90 |  │  ██████████████████████████████████████  ツールSP          │
     |  │  ● ツール特性は客観的。大量の使用実績データで高精度       │
  87 |  │                                                          │
     |  │  ████████████████████████████████████  アナリスト          │
  85 |  │  ● 定量分析×大量データで統計的パワーが高い               │
     |  │                                                          │
  84 |  │  ██████████████████████████████████  戦略エージェント      │
     |  │  ● 大量のA/B結果データにより戦略判断の根拠が強化           │
     |  │  ██████████████████████████████████  データキュレーター    │
  82 |  │  ● コンポーネント採用率のフィードバックが迅速に蓄積       │
     |  │                                                          │
  80 |  │  ████████████████████████████████  プランナー              │
     |  │  ● 多変数だが大量データで最適組合せの探索が加速           │
     |  └──────────────────────────────────────────────────────────┘
     ※ 天井はニッチや市場環境により±3%程度変動する
     ※ per-contentモデルにより日次サイクル型比+15〜20%の天井引き上げ
```

#### 天井到達後のシフト: クロスエージェント知識共有

| 段階 | 主な改善源 | 説明 |
|---|---|---|
| **天井到達前** | 個別自己改善 | 各エージェントが自身のフィードバックループで精度を向上 |
| **天井到達後** | クロスエージェント知識共有 | 個別改善の限界に達したエージェントは、他エージェントの知見を取り込む |

クロスエージェント知識共有の例:

```
リサーチャーの天井到達後:
  └→ アナリストの「どの分析が仮説confirmedにつながったか」を参照
  └→ 「confirmedにつながりやすい情報カテゴリ」を逆算して収集対象を最適化
  └→ 調査精度がさらに+3〜5%向上

プランナーの天井到達後:
  └→ リサーチャーの「トレンド変動タイミング」データを直接参照
  └→ トレンドの立ち上がり期にコンテンツを投入する精度が向上
  └→ 企画成功率がさらに+2〜4%向上
```

### 7.6 エージェント個別精度のデータベース追跡

`algorithm_performance`テーブル（または既存テーブルへのカラム追加）で個別精度を追跡する:

| カラム | 型 | 説明 |
|---|---|---|
| `id` | SERIAL | 主キー |
| `measured_at` | TIMESTAMPTZ | 精度データが記録された日時 |
| `period` | VARCHAR(10) | 集計期間（CHECK: 'daily', 'weekly', 'monthly'） |
| `hypothesis_accuracy` | NUMERIC(5,4) | 仮説的中率（0.0000〜1.0000） |
| `prediction_error` | NUMERIC(8,4) | 予測と実測の平均誤差（RMSE） |
| `learning_count` | INTEGER | 累計蓄積知見数 |
| `top_performing_niches` | JSONB | ジャンル別パフォーマンスランキング |
| `improvement_rate` | NUMERIC(5,4) | 前期比改善率 |
| `metadata` | JSONB | その他のメタデータ（仮説数、コンテンツ数、アカウント数等） |

集計クエリ例:

```sql
-- 月次精度推移
SELECT
  period,
  date_trunc('month', measured_at) AS month,
  AVG(hypothesis_accuracy) AS avg_accuracy,
  AVG(prediction_error) AS avg_prediction_error,
  MAX(learning_count) AS total_learnings,
  AVG(improvement_rate) AS avg_improvement
FROM algorithm_performance
WHERE period = 'monthly'
GROUP BY period, date_trunc('month', measured_at)
ORDER BY month;
```


## 8. アルゴリズム精度が不十分な場合の対策

### 8.1 精度低迷のシナリオと対策

#### シナリオ1: 3ヶ月後に的中率35%以下

**症状**: per-contentモデルで900〜2,400件/月のデータがあるにもかかわらず、的中率が35%を超えない。学習効率が想定を下回っている。

**原因分析チェックリスト**:

| チェック項目 | 確認方法 | 対策 |
|---|---|---|
| 仮説の粒度が粗すぎる | 仮説の変数数を確認 | 1仮説1変数に分割 |
| 測定期間が短すぎる | inconclusive率を確認 | 測定期間を延長（3日→7日） |
| ニッチが広すぎる | ニッチ別的中率を確認 | サブニッチに細分化 |
| リサーチデータが古い | market_intelの更新頻度を確認 | リサーチャーの頻度を増加 |
| 外部要因が支配的 | 時系列のバラつきを確認 | 外部変数をモデルに組み込む |

**具体的な対策**:

1. **リサーチャーの実行頻度を増加**: 数時間ごと → 1時間ごと。市場情報の鮮度を向上
2. **人間の仮説投入**: ダッシュボードから「この方向性で試して」という指示を投入
3. **仮説スコープの縮小**: 「美容全般」→「美容 × 20代 × TikTok × Before/After」
4. **A/Bテストモード**: 同一コンテンツで1変数のみ変えたA/Bペアを投稿

```
改善フロー（的中率35%以下）:

  仮説スコープ縮小
       │
  A/Bテスト実施（1変数のみ変更）
       │
  結果比較（統計的有意性を確認）
       │
  確認済みパターンを知見化
       │
  パターンに基づく新仮説生成
       │
  的中率の改善確認
       │
  改善なし → 人間介入（ドメインエキスパートの知識注入）
```

#### シナリオ2: 6ヶ月後に的中率60%以下

**症状**: 半年経ち累計5万件以上のデータがあるにもかかわらず、70%に到達しない。学習曲線が平坦化している。

**原因分析チェックリスト**:

| チェック項目 | 確認方法 | 対策 |
|---|---|---|
| 仮説カテゴリの抽象度が不適切 | カテゴリ別的中率の比較 | カテゴリ再設計 |
| ニッチ自体が不適切 | ニッチ別成長率の比較 | ニッチピボット |
| 計測頻度が不足 | データポイント数/仮説を確認 | 計測ワーカーの頻度増加 |
| 知見の再利用が不十分 | evidence_countの分布を確認（※learningsにusage_countは存在しない。componentsテーブルに存在） | プランナーの知見参照ロジック改善 |
| プラットフォーム側の変化 | 同一パターンの時系列変化を確認 | アルゴリズム変更の検知・適応 |

**具体的な対策**:

1. **仮説カテゴリの再設計**: 現在のカテゴリが現実のパターンと合っていない可能性。データドリブンでカテゴリを再構成
2. **ニッチピボットの検討**: 的中率が特定ニッチで低い場合、そのニッチからの撤退を検討
3. **計測頻度の増加**: 6時間ごと → 2時間ごと。短期的なパフォーマンス変動を捕捉
4. **外部データソースの追加**: Google Trends API、TikTok Creative Center等を統合

### 8.2 精度改善の優先順位マトリクス

```
    改善コスト（低）                    改善コスト（高）
         │                                  │
  ┌──────┼──────────────────────────────────┤
  │      │                                  │
  │ 高   │  投稿時間の最適化     リサーチャー増設      │
  │ 影   │  ハッシュタグ改善     外部データソース追加   │
  │ 響   │  フック形式テスト     ニッチ再設計          │
  │ 度   │                                  │
  │      │  ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─│
  │      │                                  │
  │ 低   │  CTA改善            プラットフォーム戦略変更│
  │ 影   │  動画長調整          エージェントLLM変更    │
  │ 響   │  音声スタイル変更     DBスキーマ再設計      │
  │ 度   │                                  │
  └──────┴──────────────────────────────────┘

  優先順位: 左上（高影響・低コスト）→ 右上（高影響・高コスト）→ 左下 → 右下
```


## 9. アカウント数・投稿数の十分性分析

### 9.1 統計的に有意なパターン発見に必要なデータ量

アルゴリズム分析レポートの知見に基づく:

| 目的 | 必要な投稿数/ニッチ | 必要な期間 | 根拠 |
|---|---|---|---|
| 初期パターン理解 | 最低50本 | 2〜3ヶ月 | テストプール突破パターンの初期認識 |
| 統計的安定性 | 100〜200本 | 4〜7ヶ月 | ニッチ内の視聴者反応パターンの安定化 |
| 一貫した成長 | 200本以上 | 7ヶ月以上 | YouTube公式データ: 200本以上で成長開始 |

### 9.2 v5.0のデータ生成能力

| Phase | 月間稼働アカウント | 投稿数/アカウント/月 | **月間データポイント** |
|---|---|---|---|
| Phase 1-2 (2〜3月) | 30〜80 | 30 | 900〜2,400 |
| Phase 3 (4月) | 100〜200 | 30 | 3,000〜6,000 |
| Phase 4 (5月) | 300〜800 | 30 | 9,000〜24,000 |
| Phase 5 (6月) | 500〜1,500 | 30 | 15,000〜45,000 |

### 9.3 ニッチ別データ充足度

10ニッチに分散した場合のニッチあたりデータ量:

| 月 | 総データポイント | ニッチ数 | 1ニッチあたり | 統計的十分性 |
|---|---|---|---|---|
| 3月 | 2,400 | 5 | 480 | 初期パターン理解に十分 |
| 4月 | 6,000 | 8 | 750 | 統計的安定性に到達 |
| 5月 | 24,000 | 10 | 2,400 | 一貫した成長に十分 |
| 6月 | 45,000 | 10 | 4,500 | 精緻なパターン分析が可能 |

### 9.4 データ品質の考慮

データ量だけでなく、データ品質も精度に影響する:

| 品質要因 | 影響 | v5.0での対策 |
|---|---|---|
| **計測の一貫性** | 同じ基準で計測しないと比較不能 | 計測ワーカーが統一フォーマットでDB保存 |
| **ノイズの排除** | 外部イベント等の一時的影響を排除 | 外れ値検出 + 移動平均で平滑化 |
| **セグメント化** | プラットフォーム・ニッチ・時間帯の区別 | `metrics`テーブルの多次元インデックス |
| **A/Bの公平性** | 同時期・同条件でのA/B比較 | プランナーがA/Bペアを同時投稿 |

### 9.5 「50アカウント」の十分性

KPI目標の2月50アカウントは、学習のためのデータ生成基盤として十分か:

```
50アカウント × 30投稿/月 = 1,500データポイント/月
                          ÷ 5ニッチ = 300/ニッチ/月
                          × 3ヶ月 = 900/ニッチ/3ヶ月

→ 3ヶ月で900本/ニッチ = 統計的安定性(100-200本)を大幅に超過
→ データ量は十分。問題はデータ品質とバリエーション
```

**結論**: 50アカウントあれば、3ヶ月以内に各ニッチで統計的に有意なパターンを発見できる。ボトルネックはデータ量ではなく**データ品質**（計測の一貫性、A/Bテストの適切な設計）。


## 10. 成長曲線のシミュレーション

### 10.1 アルゴリズム精度の12ヶ月成長曲線（per-contentモデル）

```
仮説的中率(%)
  95 |                                                    ─────── ← 天井 (90-95%)
     |                                               ───/
  90 |                                          ────/
     |                                     ────/
  85 |                                ────/
     |                           ────/
  80 |                      ────/                  ← Phase D: 高精度運用
     |                 ────/
  75 |            ────/
     |        ───/
  70 |     ──/
     |   ─/                                        ← Phase C: 精密予測
  65 |  /
     | /
  60 |/
     |
  55 |──
     |  ─                                          ← Phase B: 高速パターン認識
  50 |   ──
     |     ─
  45 |      ──
     |        ─
  40 |         ──                                   ← Phase A: 高速ベースライン構築
     |           ─
  35 |            ──
     |
  30 |──
     |
  25 |
   0 +─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────
     3月    4月    5月    6月    7月    8月    9月   10月   11月   12月

     |←Phase A→|←Phase B→|←─── Phase C ───→|←──── Phase D ────→|
     | 900-2.4k | 3k-6k  | 9k-45k/月       | 60k-105k/月        |  ← 月間学習イベント数
```

### 10.2 蓄積知見数の成長曲線

```
蓄積知見数（learnings + content_learnings昇格分）
4500 |                                                        ●
     |                                                    ●  /
4000 |                                                ●  /
     |                                            ●  /
3500 |                                        ●  /
     |                                    ●  /
3000 |                               ●   /
     |                          ●   /
2500 |                     ●   /
     |                ●   /
2000 |           ●   /
     |      ●   /
1500 |     ●   /
     |    /
1000 |   /
     |  /
 500 | /
     |/
   0 +──┬──┬──┬──┬──┬──┬──┬──┬──┬──
     3月 4月 5月 6月 7月 8月 9月 10月 11月 12月

     per-contentモデルにより知見蓄積が加速:
     3月: 30-60 → 6月: 800-1,500 → 12月: 4,000+
     ※ content_learningsは別途 450,000件（6ヶ月累計）蓄積
```

### 10.3 コンテンツ品質スコアの成長曲線

```
平均品質スコア (1-10)
  10 |
   9 |
   8 |                                              ──────── ← 目標
     |                                         ────/
   7 |                                    ────/
     |                               ────/
   6 |                          ────/
     |                     ────/
   5 |                ────/
     |           ────/
   4 |      ────/
     | ────/
   3 |/
     |
   2 |
   1 |
   0 +─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────
     3月    4月    5月    6月    7月    8月    9月   10月   11月   12月

     品質改善はアルゴリズム精度に2〜4週間遅れて追従する
```

### 10.4 総合シミュレーション --- 12ヶ月の全指標

```
┌──────────────────────────────────────────────────────────────────┐
│                      v5.0 12ヶ月シミュレーション                   │
├─────┬────────┬──────┬──────┬──────┬──────┬──────────────────────┤
│ 月  │ 的中率  │ 誤差  │ 知見数 │ 品質  │ アカ数 │ 月間Imp(千)       │
├─────┼────────┼──────┼──────┼──────┼──────┼──────────────────────┤
│ 3月 │ 30%    │ 55%  │ 45   │ 4.8  │ 75   │ 1,125              │
│ 4月 │ 48%    │ 32%  │ 180  │ 5.8  │ 150  │ 3,600              │
│ 5月 │ 63%    │ 20%  │ 520  │ 6.5  │ 550  │ 24,750             │
│ 6月 │ 76%    │ 15%  │ 1,150│ 7.2  │ 1,000│ 75,000             │
│ 7月 │ 80%    │ 12%  │ 1,800│ 7.6  │ 1,400│ 147,000            │
│ 8月 │ 84%    │ 10%  │ 2,400│ 8.0  │ 1,800│ 226,800            │
│ 9月 │ 87%    │ 8%   │ 3,000│ 8.3  │ 2,200│ 330,000            │
│10月 │ 89%    │ 7%   │ 3,500│ 8.5  │ 2,600│ 442,000            │
│11月 │ 91%    │ 6%   │ 3,800│ 8.7  │ 3,000│ 570,000            │
│12月 │ 92%    │ 6%   │ 4,200│ 8.8  │ 3,500│ 735,000            │
├─────┴────────┴──────┴──────┴──────┴──────┴──────────────────────┤
│ 的中率: confirmed/(confirmed+rejected)                          │
│ 誤差: avg(|predicted - actual| / actual)                       │
│ 品質: 10点満点の加重平均スコア                                     │
│ Imp: 1アカウントあたりの月間平均Imp × 稼働アカウント数 × 30日       │
└──────────────────────────────────────────────────────────────────┘
```

### 10.5 楽観/悲観シナリオの比較

```
的中率(%)
  95 |                                                     ── ← 楽観
  90 |                                                ────/     仮説品質が高い + ニッチが適切
  85 |                                           ────/          + クロスニッチ効果最大
  80 |                                      ────/          ── ← 中央値
  75 |                                 ────/          ────/     標準的な進行（本レポートの予測値）
  70 |                            ────/          ────/
  65 |                       ────/          ────/
  60 |                  ────/          ────/               ── ← 悲観
  55 |             ────/          ────/               ────/     データ品質問題 or ニッチ不適合
  50 |        ────/          ────/               ────/
  45 |   ────/          ────/               ────/
  40 |──/          ────/               ────/
  35 |        ────/               ────/
  30 |●  ────/               ────/
  25 |  /               ────/
  20 |             ────/
   0 +─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────
     3月    4月    5月    6月    7月    8月    9月   10月   11月   12月

  楽観: 95%到達。ニッチ選定が最適でクロスニッチ学習が最大効果
  中央値: 92%。本レポートの標準予測値
  悲観: 70%止まり。データ品質問題やプラットフォーム変更の影響
```


## 11. リスクと限界

### 11.1 精度予測の不確実性

| リスク | 影響 | 緩和策 |
|---|---|---|
| **プラットフォームのアルゴリズム大幅変更** | 蓄積知見が無効化される可能性 | 知見に有効期限を設定。定期的な再検証 |
| **AIコンテンツ検出の強化** | 投稿自体が制限される可能性 | コンテンツの人間性を高める工夫。ハイブリッド戦略 |
| **ニッチの市場飽和** | 特定ニッチで成長が停滞 | ポートフォリオ分散。アナリストの早期検知 |
| **仮説の「局所最適」への陥没** | 特定パターンに固執し、新しいアプローチを試さない | 探索率を10〜20%に設定（system_settings: `EXPLORATION_RATE`、デフォルト: 0.15） |
| **計測データの遅延** | プラットフォームAnalyticsの反映に24〜48時間 | 遅延を織り込んだサイクル設計 |

### 11.2 モデルの限界

本レポートの精度予測は以下の前提に基づいており、前提が崩れると予測も崩れる:

1. **v5.0が計画通り開発される**: Phase 1〜5が予定通り完了する前提
2. **LLMの推論能力が維持される**: Claude Opus/Sonnetの性能が低下しない前提
3. **データの質が維持される**: 計測ワーカーが正確にメトリクスを収集する前提
4. **市場環境が急変しない**: プラットフォームのポリシー大変更がない前提

### 11.3 過学習（オーバーフィッティング）のリスク

特定のニッチ・プラットフォーム・時期のデータに過剰適合するリスク:

```
正常な学習:
  一般パターン → ニッチ固有パターン → 時期に応じた微調整

過学習:
  一般パターン → 「2月のTikTok美容ニッチの火曜日17時投稿」のみに最適化
                 → 3月に環境が変わると全く機能しない
```

**対策**:
- 仮説のテストデータと訓練データを分離（20%のアカウントをテスト用に確保）
- 知見の`confidence`が0.8以上のものだけを横展開
- 探索率（全サイクルの10〜20%を「確認済みパターン外」の新規仮説に充当）（system_settings: `EXPLORATION_RATE`、デフォルト: 0.15）


## 12. 判断ロジック・数式定義

本セクションでは、アルゴリズム精度に関わる各判断の数式・閾値・アルゴリズムを定義する。全ての閾値は `system_settings` テーブルで管理され、ハードコーディングは禁止される。04-agent-design.md セクション17の数式定義と整合する。

### 12.1 仮説的中率 (hypothesis_accuracy)

```
hypothesis_accuracy = confirmed_count / (confirmed_count + rejected_count)
```

- `inconclusive` は分母から除外
- 記録先: `algorithm_performance.hypothesis_accuracy`
- 算出タイミング: `cycle_review` 分析の実行時

### 12.2 予測誤差 (prediction_error)

```
prediction_error = AVG(|predicted_kpis[key] - actual_kpis[key]| / NULLIF(actual_kpis[key], 0))
```

- `predicted_kpis`, `actual_kpis` は JSONB（複数KPI指標を含む）
- 各KPI指標（views, engagement_rate, completion_rate等）の相対誤差の平均
- `NULLIF(actual, 0)` により actual=0 の場合は NULL を返し、ゼロ除算を回避する
- 記録先: `algorithm_performance.prediction_error`

### 12.3 仮説判定 (verdict)

`predicted_kpis` / `actual_kpis` は JSONB で複数KPI指標を含む。全KPI指標の相対誤差の平均でverdictを判定する。

```
verdict判定式:
  prediction_error = avg(|predicted_kpis[i] - actual_kpis[i]| / actual_kpis[i]) for all KPIs
    ※ actual_kpis[i] = 0 の場合:
      predicted_kpis[i] = 0 なら error = 0（両方ゼロなら一致とみなす）
      predicted_kpis[i] ≠ 0 なら error = 1.0（ゼロに対する非ゼロ予測は最大誤差）

  verdict =
    IF prediction_error <= HYPOTHESIS_CONFIRM_THRESHOLD (system_settings、デフォルト: 0.3)
      THEN 'confirmed'
    ELIF prediction_error >= HYPOTHESIS_INCONCLUSIVE_THRESHOLD (system_settings、デフォルト: 0.5)
      THEN 'rejected'
    ELSE 'inconclusive'

  ※ データ不足時 (メトリクス < ANALYSIS_MIN_SAMPLE_SIZE (system_settings、デフォルト: 5) サンプル):
    verdict = 'inconclusive' を強制（統計的に有意な判定が不可能なため）
```

| 設定キー | デフォルト | 意味 |
|---|---|---|
| `HYPOTHESIS_CONFIRM_THRESHOLD`（system_settings、デフォルト: 0.3） | 0.3 | 予測精度70%以上で `confirmed` |
| `HYPOTHESIS_INCONCLUSIVE_THRESHOLD`（system_settings、デフォルト: 0.5） | 0.5 | 誤差50%以上で `rejected`、30〜50%は `inconclusive` |
| `ANALYSIS_MIN_SAMPLE_SIZE`（system_settings、デフォルト: 5） | 5 | この数未満のサンプルでは `inconclusive` を強制 |

判定の信頼度:

```
confidence = 1.0 - AVG(per_kpi_error)
-- confirmed: confidence 0.7〜1.0
-- inconclusive: confidence 0.5〜0.7
-- rejected: confidence < 0.5
```

### 12.4 異常検知 (anomaly_detection)

```
異常検知式:
  anomaly = |metric_value - rolling_mean| > ANOMALY_DETECTION_SIGMA × rolling_stddev

  rolling_mean / rolling_stddev: 直近 ANOMALY_DETECTION_WINDOW_DAYS (system_settings、デフォルト: 14) 日の
    同プラットフォーム・同ニッチのメトリクス平均/標準偏差
  ANOMALY_DETECTION_SIGMA: system_settings (デフォルト: 2.0)

  データ不足時:
    - 利用可能な全期間を使用、最低 ANOMALY_MIN_DATAPOINTS (system_settings、デフォルト: 7) データポイント必要
    - 7データポイント未満: 異常検知スキップ (ログに WARN)
```

```sql
-- 基準期間: ANOMALY_DETECTION_WINDOW_DAYS（system_settings、デフォルト: 14日）
-- 閾値: ANOMALY_DETECTION_SIGMA（system_settings、デフォルト: 2.0）
-- 最小データポイント: ANOMALY_MIN_DATAPOINTS（system_settings、カテゴリ: agent、デフォルト: 7）

WITH baseline AS (
    SELECT
        p.account_id,
        AVG(m.engagement_rate) as mean_er,
        STDDEV(m.engagement_rate) as std_er,
        AVG(m.completion_rate) as mean_cr,
        STDDEV(m.completion_rate) as std_cr,
        AVG(m.views) as mean_views,
        STDDEV(m.views) as std_views,
        COUNT(*) as datapoint_count
    FROM metrics m
    JOIN publications p ON m.publication_id = p.id
    WHERE m.measured_at >= (NOW() - make_interval(days => :window_days))
    GROUP BY p.account_id
    HAVING COUNT(*) >= :min_datapoints  -- ANOMALY_MIN_DATAPOINTS (デフォルト: 7)
)
SELECT m.*, b.*
FROM metrics m
JOIN publications p ON m.publication_id = p.id
JOIN baseline b ON p.account_id = b.account_id
WHERE ABS(m.engagement_rate - b.mean_er) > :sigma * b.std_er
   OR ABS(m.completion_rate - b.mean_cr) > :sigma * b.std_cr
   OR ABS(m.views - b.mean_views) > :sigma * b.std_views;
-- HAVING句でデータポイント不足時はbaseline CTE が空 → JOINで結果なし → 異常検知スキップ
```

関連する system_settings:

| 設定キー | デフォルト | カテゴリ | 説明 |
|---|---|---|---|
| `ANOMALY_DETECTION_WINDOW_DAYS` | 14 | agent | 異常検知の基準期間（日）。不足時は利用可能な全期間を使用 |
| `ANOMALY_DETECTION_SIGMA` | 2.0 | agent | 標準偏差閾値。大きくすると感度が下がる |
| `ANOMALY_MIN_DATAPOINTS` | 7 | agent | この数未満のデータポイントでは異常検知をスキップし、WARNログを出力 |

異常の分類:

- **正の異常（バイラル）**: 値が mean + sigma × std を超過 → 成功パターン分析を優先実行
- **負の異常（急落）**: 値が mean - sigma × std を下回る → 問題調査タスクを自動生成

### 12.5 コンポーネント品質スコア (quality_score)

```
quality_score = Σ(weight_i × normalized_metric_i)

重み (system_settings):
  QUALITY_WEIGHT_COMPLETION  = 0.35 (完視聴率)
  QUALITY_WEIGHT_ENGAGEMENT  = 0.25 (エンゲージメント率)
  QUALITY_WEIGHT_SHARE       = 0.20 (シェア率)
  QUALITY_WEIGHT_RETENTION   = 0.15 (リテンション率)
  QUALITY_WEIGHT_SENTIMENT   = 0.05 (センチメント分析)

normalized_metric = min(1.0, actual / platform_niche_median)
※ platform_niche_median: learningsテーブルの過去データから動的算出
※ データ不足時 (< ANALYSIS_MIN_SAMPLE_SIZE (system_settings、デフォルト: 5) サンプル):
   system_settingsのデフォルト中央値（下記スケーリング基準値）を使用
```

normalized_metric を0.0〜1.0に正規化した後、10倍して0-10点スケールに変換する:

| メトリクス | ウェイト設定キー | デフォルト | スケーリング関数 | スケーリング基準値（デフォルト中央値） |
|-----------|----------------|-----------|----------------|------------------|
| completion_rate | `QUALITY_WEIGHT_COMPLETION`（system_settings） | 0.35 | `min(10, rate / 0.07)` | 70%で10点満点（優秀なショート動画の基準） |
| engagement_rate | `QUALITY_WEIGHT_ENGAGEMENT`（system_settings） | 0.25 | `min(10, rate / 0.003)` | 3%で10点満点（バイラル動画の基準） |
| share_rate | `QUALITY_WEIGHT_SHARE`（system_settings） | 0.20 | `min(10, rate / 0.005)` | 0.5%で10点満点 |
| 3秒離脱率 | `QUALITY_WEIGHT_RETENTION`（system_settings） | 0.15 | `min(10, (1 - rate) / 0.06)` | 40%以下で10点満点（40%は業界平均） |
| ポジティブ感情比率 | `QUALITY_WEIGHT_SENTIMENT`（system_settings） | 0.05 | `min(10, ratio / 0.06)` | 60%以上で10点満点 |

> **動的中央値**: 十分なデータ（>= `ANALYSIS_MIN_SAMPLE_SIZE`）が蓄積された後は、上記の固定基準値の代わりにlearningsテーブルの同プラットフォーム・同ニッチの実績中央値を `platform_niche_median` として動的に算出し、より正確なスコアリングを行う。

**計算例**:

```
completion_rate = 0.78 → scaled = min(10, 0.78/0.07) = 10.0 (cap)
engagement_rate = 0.025 → scaled = min(10, 0.025/0.003) = 8.33
share_rate = 0.003 → scaled = min(10, 0.003/0.005) = 6.0
3秒離脱率 = 0.35 → scaled = min(10, (1-0.35)/0.06) = 10.0 (cap)
ポジティブ感情 = 0.55 → scaled = min(10, 0.55/0.06) = 9.17

quality_score = 10.0×0.35 + 8.33×0.25 + 6.0×0.20 + 10.0×0.15 + 9.17×0.05
             = 3.50 + 2.08 + 1.20 + 1.50 + 0.46
             = 8.74
```

### 12.6 学習信頼度の更新ルール

```
confidence更新式:
  初期confidence = 0.5

  verdict = 'confirmed':
    confidence_new = min(0.95, confidence_old + (1 - confidence_old) × LEARNING_SUCCESS_INCREMENT)
    ※ LEARNING_SUCCESS_INCREMENT = 0.10 (system_settings)
    ※ 上限0.95: 完全な確信（1.0）は許容しない（常に改善余地を残す）
    ※ 減衰項 (1 - confidence_old) により、高confidence時の増加幅が自然に縮小する
    times_successful += 1

  verdict = 'inconclusive':
    confidence_new = confidence_old + CONFIDENCE_INCREMENT_INCONCLUSIVE
    ※ CONFIDENCE_INCREMENT_INCONCLUSIVE = 0.02 (system_settings)
    ※ データ不足でも「検証を試みた」こと自体に微小な正の評価

  verdict = 'rejected':
    confidence_new = max(0.05, confidence_old - LEARNING_FAILURE_DECREMENT)
    ※ LEARNING_FAILURE_DECREMENT = 0.15 (system_settings)
    ※ 下限0.05: 完全なゼロにはしない（復活の余地を残す）

  ※ evidence_count >= LEARNING_AUTO_PROMOTE_COUNT (system_settings、デフォルト: 10) で "mature" 判定
  ※ mature learnings は confidence >= LEARNING_CONFIDENCE_THRESHOLD (0.7) のものだけが
    プランナーに推奨される
  ※ confidence < LEARNING_DEACTIVATE_THRESHOLD (0.2) で自動非活性化 (is_active=false)
```

| 設定キー | デフォルト | 説明 |
|---|---|---|
| `LEARNING_SUCCESS_INCREMENT`（system_settings） | 0.1 | confirmed時のconfidence増分ベース値 |
| `CONFIDENCE_INCREMENT_INCONCLUSIVE`（system_settings） | 0.02 | inconclusive時のconfidence微増量 |
| `LEARNING_FAILURE_DECREMENT`（system_settings） | 0.15 | rejected時のconfidence減分（失敗の方が影響大） |
| `LEARNING_CONFIDENCE_THRESHOLD`（system_settings） | 0.7 | この値以上で「有効」として積極参照 |
| `LEARNING_DEACTIVATE_THRESHOLD`（system_settings） | 0.2 | この値未満で自動非活性化 (is_active=false) |

有効判定:

```
confidence >= LEARNING_CONFIDENCE_THRESHOLD (0.7) → 積極的に参照（mature learningsとしてプランナーに推奨）
confidence 0.2〜0.7 → 参照はするが優先度低
confidence < LEARNING_DEACTIVATE_THRESHOLD (0.2) → is_active=false に自動変更、参照対象から除外
```

自動昇格条件:

```
evidence_count >= LEARNING_AUTO_PROMOTE_COUNT (デフォルト: 10)
AND confidence >= 0.8
→ learningsテーブルに昇格（全エージェント参照可能）
```

| 設定キー | デフォルト | 説明 |
|---|---|---|
| `LEARNING_AUTO_PROMOTE_COUNT`（system_settings） | 10 | 昇格に必要なevidence_count（検証回数） |
| `LEARNING_AUTO_PROMOTE_ENABLED`（system_settings） | false | trueの場合は自動昇格、falseの場合はアナリストの月次レビューで承認 |

### 12.7 リソース配分計算

```
-- プランナー数の算出
planner_count = CEIL(active_account_count / PLANNER_ACCOUNTS_PER_INSTANCE)
-- 例: 50 accounts / 50 = 1 planner, 160 / 50 = 4 planners

-- 日次制作目標
daily_production_target = active_account_count × MAX_POSTS_PER_ACCOUNT_PER_DAY
-- 例: 50 × 2 = 100 videos/day

-- 1動画あたり予算上限
budget_per_video = DAILY_BUDGET_LIMIT_USD / daily_production_target
-- 例: $100 / 100 = $1.00/video → Standard Lipsync推奨

-- fal.ai並列タスク配分
concurrent_per_planner = MAX_CONCURRENT_PRODUCTIONS / planner_count
-- 例: 5 / 1 = 5 concurrent tasks per planner
```

| 設定キー | デフォルト | 説明 |
|---|---|---|
| `PLANNER_ACCOUNTS_PER_INSTANCE`（system_settings） | 50 | 1プランナーの担当アカウント数上限 |
| `MAX_POSTS_PER_ACCOUNT_PER_DAY`（system_settings） | 2 | 1アカウントの1日あたり最大投稿数 |
| `DAILY_BUDGET_LIMIT_USD`（system_settings） | 100 | 1日あたりのfal.ai等外部API予算上限(USD) |
| `MAX_CONCURRENT_PRODUCTIONS`（system_settings） | 5 | 同時制作可能な動画数の上限 |


## 13. データ変換ロジック

本セクションでは、データがシステム内の各分析ステージ間でどのように変換・伝搬されるかを定義する。

### 13.1 metrics → hypothesis verdict

```
1. metricsテーブルから対象publicationのデータ取得
2. 該当contentのhypothesis_idから仮説のpredicted_kpisを取得
3. 各KPI指標について相対誤差を計算:
   error[key] = |predicted[key] - actual[key]| / NULLIF(actual[key], 0)  -- actual=0の場合はNULL
4. 全KPI指標の平均誤差でverdict判定（セクション12.3参照）
5. hypotheses.verdict, hypotheses.actual_kpis, hypotheses.confidence を更新
6. analyses レコードを生成:
   {
     "analysis_type": "hypothesis_verification",
     "findings": {
       "hypothesis_id": ...,
       "predicted": {...},
       "actual": {...},
       "per_kpi_errors": {...},
       "verdict": "confirmed|rejected|inconclusive",
       "confidence": 0.XX
     },
     "recommendations": ["判定に基づく次の施策提案"]
   }
```

### 13.2 learnings + content_learnings → 次コンテンツのプロンプト注入

```
1. MCP Serverのget_relevant_learningsツールが呼ばれる
2. 現在のコンテキスト（niche, platform, content_format）をembedding化
3. pgvectorでcosine similarity >= LEARNING_SIMILARITY_THRESHOLD の知見を検索
   （system_settings: LEARNING_SIMILARITY_THRESHOLD、デフォルト: 0.8）
4. confidence >= LEARNING_CONFIDENCE_THRESHOLD のもののみフィルタ
   （system_settings: LEARNING_CONFIDENCE_THRESHOLD、デフォルト: 0.7）
5. 上位 MAX_LEARNINGS_PER_CONTEXT 件をJSON配列として返却
   （system_settings: MAX_LEARNINGS_PER_CONTEXT、デフォルト: 20）
6. エージェントのプロンプトの「蓄積された知見」セクションに注入:

   ## 関連する蓄積知見
   1. [confidence: 0.85] beauty/hookフォーマット: 「質問形式のフックはengagement_rateが1.5倍」
   2. [confidence: 0.73] timing: 「20-22時投稿はcompletion_rateが高い」
   ...
```

### 13.3 hypothesis → content plan 変換

```
1. 戦略エージェントのポリシーとプランナーの知見を入力
2. 検証したい仮説を選択（新規作成 or 再検証）:
   - 新規: リサーチャーのmarket_intelとlearningsから仮説を生成
   - 再検証: inconclusiveの仮説から条件を変えて再テスト
3. 仮説のcategoryに基づいてコンポーネント選択:
   - hook_format仮説 → hookコンポーネントを変数として選択
   - posting_time仮説 → 同じコンテンツで時刻を変えて投稿
   - content_length仮説 → duration_secondsを変えたシナリオ
4. content レコード作成:
   {
     "content_format": "short_video",
     "hypothesis_id": 新仮説のID,
     "status": "planned",
     "recipe_id": Tool Specialistの推奨レシピ
   }
5. content_sections作成（hook/body/ctaのコンポーネント割当）
6. hypotheses レコード作成:
   {
     "statement": "beautyニッチでは質問形式フックがengagement_rate 3%以上を達成する",
     "category": "hook_format",
     "predicted_kpis": {"engagement_rate": 0.03, "completion_rate": 0.7},
     "confidence": 0.5 (初期値)
   }
```

### 13.4 反省 → 個別学習 → グローバル知見 変換

```
1. マイクロサイクル: 各コンテンツのverdict確定時にcontent_learningsに自動記録
   マクロサイクル: 日次集計時にエージェントが自己反省 (agent_reflections)
2. what_went_well + what_to_improve からパターン抽出:
   - 「同じ状況で同じ判断が成功した」→ 正のパターン
   - 「同じ種類のエラーが繰り返された」→ 負のパターン
3. パターンをagent_individual_learnings に保存:
   {
     "category": "content|timing|audience|platform|niche|tool_characteristics|...",
     "content": "抽出されたパターンの記述",
     "confidence": 0.5 (初期),
     "source_reflection_id": 元のreflection UUID
   }
4. embedding生成して類似既存知見を検索:
   - cosine >= COMPONENT_DUPLICATE_THRESHOLD → 既存知見のconfidenceを更新（evidenceカウント増）
     （system_settings: COMPONENT_DUPLICATE_THRESHOLD、デフォルト: 0.9）
   - cosine 0.7〜0.9 → 関連知見としてリンク
   - cosine < 0.7 → 新規知見として保存
5. 昇格条件チェック（セクション12.6参照）:
   times_successful >= LEARNING_AUTO_PROMOTE_COUNT (デフォルト: 10)
   AND confidence >= 0.8
   → learnings テーブルにコピー（全エージェント参照可能）
```


## 14. 結論

### v5.0アルゴリズム精度の全体像

```
┌──────────────────────────────────────────────────────────────────┐
│                                                                  │
│   月     3月   4月   5月   6月   9月   12月                       │
│          │     │     │     │     │     │                         │
│  的中率  30%   48%   63%   76%   87%   92%                       │
│          │     │     │     │     │     │                         │
│          ▼     ▼     ▼     ▼     ▼     ▼                         │
│  品質    4.8   5.8   6.5   7.2   8.3   8.8                      │
│          │     │     │     │     │     │                         │
│          ▼     ▼     ▼     ▼     ▼     ▼                         │
│  知見    45    180   520  1,150  3,000 4,200                     │
│                                                                  │
│  Phase:  A(高速BL) B(高速認識) C(精密予測) D(高精度運用)           │
│  学習/月: 900-2.4k  3k-6k      9k-45k     60k-105k              │
│                                                                  │
├──────────────────────────────────────────────────────────────────┤
│  エージェント個別精度（12ヶ月後予測）                                │
│                                                                  │
│  リサーチャー     ██████████████████████████████████████████ 92%  │
│  ツールSP        █████████████████████████████████████████ 90%   │
│  アナリスト       ███████████████████████████████████████ 87%     │
│  戦略エージェント ██████████████████████████████████████ 84%      │
│  プランナー       ████████████████████████████████████ 82%        │
│                                                                  │
│  ★ per-content学習 → 好循環 → システム全体の的中率92%達成         │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

### 要点の整理

1. **per-content学習で精度が急速に向上**: 初期30% → 6ヶ月76% → 12ヶ月92%。毎回のコンテンツ制作が学習イベントとなり、日次サイクル型の1,000〜3,000倍の学習速度を実現する

2. **天井は90〜95%**: per-contentモデルの圧倒的データ量（月間15,000〜105,000件）により、統計的にノイズを排除可能。残る5〜10%はプラットフォームアルゴリズム変更やバイラル偶発性等の予測不能な外部イベントのみ

3. **pgvectorが学習を加速する**: クロスニッチの知見転用により、単一ニッチで学習するより2〜3倍速く精度が向上する。content_learningsの450,000件（6ヶ月累計）がベクトル検索の基盤

4. **品質が量を圧倒する**: 的中率50%で50本投稿するより、的中率90%で30本投稿する方が総インプレッションが圧倒的に高い。92%の精度はエキスパートマーケターを大幅に上回るレベル

5. **人間介入のレバレッジが高い**: ダッシュボードからの仮説投入や参考コンテンツ指定は、特に初期（3〜4ヶ月目）の学習加速に効果的

6. **50アカウントでデータは十分**: 50アカウント × 30投稿/月 = 1,500データポイント/月。per-contentモデルにより初月から統計的なパターン発見が可能

7. **エージェント個別精度の追跡がシステム全体を最適化する**: リサーチャー(92%)、ツールSP(90%)、アナリスト(87%)、戦略エージェント(84%)、プランナー(82%)がそれぞれの天井に向かって個別に改善し、好循環により全体の仮説的中率92%を達成する

8. **全ての閾値・数式はsystem_settingsで管理**: 仮説判定閾値、品質スコアウェイト、異常検知パラメータ、学習昇格条件等の全設定値はDBに保存され、ダッシュボードから動的に調整可能（セクション12参照）

### 次のアクション

| アクション | 担当 | 時期 |
|---|---|---|
| `hypotheses`テーブルの精度集計クエリを設計 | Phase 1開発 | 3月 |
| pgvectorのembeddingモデル選定とベンチマーク | Phase 1開発 | 3月 |
| `algorithm_performance`テーブルのスキーマ設計と実装 | Phase 1開発 | 3月 |
| エージェント別精度指標（調査精度・分析品質・企画成功率・戦略的中率）の計測ロジック実装 | Phase 2開発 | 4月 |
| 品質スコアの重みパラメータを初期設定 | Phase 2開発 | 4月 |
| 各エージェントの自己反省プロンプトの設計・テスト | Phase 3開発 | 5月 |
| 探索率（exploration rate）の初期値を10%に設定 | Phase 3開発 | 5月 |
| エージェント個別精度ダッシュボード（種別ごとの推移グラフ）の実装 | Phase 5開発 | 6月 |
| 精度ダッシュボードの実装 | Phase 5開発 | 6月 |
| クロスエージェント知識共有の波及効果モニタリング設定 | Phase 5開発 | 6月 |
| 過学習検知アラートの設定 | Phase 5開発 | 6月 |
